{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "faster-rcnn.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "FIqnjbWYsuQw",
        "2FKFq8RXs6bs",
        "MFyCeiBb9BbS"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "dW2W17o-p7SX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44ddf9d9-d979-4097-c667-5d82cf8cb599"
      },
      "source": [
        "!pip install tensorflow_gpu==1.15"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow_gpu==1.15\n",
            "  Downloading tensorflow_gpu-1.15.0-cp37-cp37m-manylinux2010_x86_64.whl (411.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 411.5 MB 7.0 kB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_gpu==1.15) (1.15.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow_gpu==1.15) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow_gpu==1.15) (3.3.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow_gpu==1.15) (0.37.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_gpu==1.15) (1.1.0)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading gast-0.2.2.tar.gz (10 kB)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_gpu==1.15) (0.8.1)\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "  Downloading tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503 kB)\n",
            "\u001b[K     |████████████████████████████████| 503 kB 44.0 MB/s \n",
            "\u001b[?25hCollecting keras-applications>=1.0.8\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 6.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_gpu==1.15) (1.21.6)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow_gpu==1.15) (1.46.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_gpu==1.15) (1.0.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow_gpu==1.15) (1.14.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow_gpu==1.15) (1.1.2)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "  Downloading tensorboard-1.15.0-py3-none-any.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 34.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow_gpu==1.15) (3.17.3)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow_gpu==1.15) (3.1.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow_gpu==1.15) (57.4.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow_gpu==1.15) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow_gpu==1.15) (3.3.7)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow_gpu==1.15) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow_gpu==1.15) (3.8.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow_gpu==1.15) (4.2.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.8->tensorflow_gpu==1.15) (1.5.2)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-py3-none-any.whl size=7554 sha256=ebdb2d9b0f852042c8e6ac72974b910e8e46e0887c8f9eb60457212fa5570d34\n",
            "  Stored in directory: /root/.cache/pip/wheels/21/7f/02/420f32a803f7d0967b48dd823da3f558c5166991bfd204eef3\n",
            "Successfully built gast\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, keras-applications, gast, tensorflow-gpu\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.8.0\n",
            "    Uninstalling tensorflow-estimator-2.8.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.8.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.8.0\n",
            "    Uninstalling tensorboard-2.8.0:\n",
            "      Successfully uninstalled tensorboard-2.8.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.5.3\n",
            "    Uninstalling gast-0.5.3:\n",
            "      Successfully uninstalled gast-0.5.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.8.0+zzzcolab20220506162203 requires tf-estimator-nightly==2.8.0.dev2021122109, which is not installed.\n",
            "tensorflow 2.8.0+zzzcolab20220506162203 requires tensorboard<2.9,>=2.8, but you have tensorboard 1.15.0 which is incompatible.\n",
            "tensorflow-probability 0.16.0 requires gast>=0.3.2, but you have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "Successfully installed gast-0.2.2 keras-applications-1.0.8 tensorboard-1.15.0 tensorflow-estimator-1.15.1 tensorflow-gpu-1.15.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy==1.19.5\n",
        "!pip uninstall -y pycocotools\n",
        "!pip install pycocotools --no-binary pycocotools"
      ],
      "metadata": {
        "id": "0y62xfiOCSJg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 839
        },
        "outputId": "d5776919-7d8d-49f6-aec8-9b12832b8f0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy==1.19.5\n",
            "  Downloading numpy-1.19.5-cp37-cp37m-manylinux2010_x86_64.whl (14.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 14.8 MB 37.5 MB/s \n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.21.6\n",
            "    Uninstalling numpy-1.21.6:\n",
            "      Successfully uninstalled numpy-1.21.6\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.8.0 requires tf-estimator-nightly==2.8.0.dev2021122109, which is not installed.\n",
            "tensorflow 2.8.0 requires numpy>=1.20, but you have numpy 1.19.5 which is incompatible.\n",
            "tensorflow 2.8.0 requires tensorboard<2.9,>=2.8, but you have tensorboard 1.15.0 which is incompatible.\n",
            "tensorflow-probability 0.16.0 requires gast>=0.3.2, but you have gast 0.2.2 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed numpy-1.19.5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: pycocotools 2.0.4\n",
            "Uninstalling pycocotools-2.0.4:\n",
            "  Successfully uninstalled pycocotools-2.0.4\n",
            "Collecting pycocotools\n",
            "  Downloading pycocotools-2.0.4.tar.gz (106 kB)\n",
            "\u001b[K     |████████████████████████████████| 106 kB 32.3 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pycocotools) (1.19.5)\n",
            "Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from pycocotools) (3.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools) (3.0.8)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools) (1.4.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib>=2.1.0->pycocotools) (4.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib>=2.1.0->pycocotools) (1.15.0)\n",
            "Building wheels for collected packages: pycocotools\n",
            "  Building wheel for pycocotools (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycocotools: filename=pycocotools-2.0.4-cp37-cp37m-linux_x86_64.whl size=265198 sha256=b2ea25e2a8686e42a468d3ef110c9bdbb5d76b7b976843dc64af7edcd95e19f3\n",
            "  Stored in directory: /root/.cache/pip/wheels/a3/5f/fa/f011e578cc76e1fc5be8dce30b3eb9fd00f337e744b3bba59b\n",
            "Successfully built pycocotools\n",
            "Installing collected packages: pycocotools\n",
            "Successfully installed pycocotools-2.0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhzxsJb3dpWq"
      },
      "source": [
        "## Configs and Hyperparameters\n",
        "\n",
        "Support a variety of models, you can find more pretrained model from [Tensorflow detection model zoo: COCO-trained models](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md#coco-trained-models), as well as their pipline config files in [object_detection/samples/configs/](https://github.com/tensorflow/models/tree/master/research/object_detection/samples/configs)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gnNXNQCjdniL"
      },
      "source": [
        "# If you forked the repo, you can replace the link.\n",
        "repo_url = 'https://github.com/roboflow-ai/tensorflow-object-detection-faster-rcnn'\n",
        "\n",
        "# Number of training steps - 1000 will train very quickly, but more steps will increase accuracy.\n",
        "num_steps = 50000  # 200000 to improve\n",
        "\n",
        "# Number of evaluation steps.\n",
        "num_eval_steps = 50\n",
        "\n",
        "MODELS_CONFIG = {\n",
        "    'ssd_mobilenet_v2': {\n",
        "        'model_name': 'ssd_mobilenet_v2_coco_2018_03_29',\n",
        "        'pipeline_file': 'ssd_mobilenet_v2_coco.config',\n",
        "        'batch_size': 1\n",
        "    },\n",
        "    'faster_rcnn_inception_v2': {\n",
        "        'model_name': 'faster_rcnn_inception_v2_coco_2018_01_28',\n",
        "        'pipeline_file': 'faster_rcnn_inception_v2_pets.config',\n",
        "        'batch_size': 1\n",
        "    },\n",
        "    'rfcn_resnet101': {\n",
        "        'model_name': 'rfcn_resnet101_coco_2018_01_28',\n",
        "        'pipeline_file': 'rfcn_resnet101_pets.config',\n",
        "        'batch_size': 8\n",
        "    }\n",
        "}\n",
        "\n",
        "# Pick the model you want to use\n",
        "# Select a model in `MODELS_CONFIG`.\n",
        "selected_model = 'faster_rcnn_inception_v2'\n",
        "\n",
        "# Name of the object detection model to use.\n",
        "MODEL = MODELS_CONFIG[selected_model]['model_name']\n",
        "\n",
        "# Name of the pipline file in tensorflow object detection API.\n",
        "pipeline_file = MODELS_CONFIG[selected_model]['pipeline_file']\n",
        "\n",
        "# Training batch size fits in Colabe's Tesla K80 GPU memory for selected model.\n",
        "batch_size = MODELS_CONFIG[selected_model]['batch_size']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4V-XE6kbkc1"
      },
      "source": [
        "## Clone the `tensorflow-object-detection` repository or your fork."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxc3DmvLQF3z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f56e00f-a8d8-4c2d-f14b-9f001cc61867"
      },
      "source": [
        "import os\n",
        "\n",
        "%cd /content\n",
        "\n",
        "repo_dir_path = os.path.abspath(os.path.join('.', os.path.basename(repo_url)))\n",
        "\n",
        "!git clone {repo_url}\n",
        "%cd {repo_dir_path}\n",
        "!git pull"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'tensorflow-object-detection-faster-rcnn'...\n",
            "remote: Enumerating objects: 885, done.\u001b[K\n",
            "remote: Total 885 (delta 0), reused 0 (delta 0), pack-reused 885\u001b[K\n",
            "Receiving objects: 100% (885/885), 24.83 MiB | 14.65 MiB/s, done.\n",
            "Resolving deltas: 100% (428/428), done.\n",
            "/content/tensorflow-object-detection-faster-rcnn\n",
            "Already up to date.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bI8__uNS8-ns"
      },
      "source": [
        "## Install required packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecpHEnka8Kix",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a554bc3-770a-40f1-eb37-8529b32babc5"
      },
      "source": [
        "%cd /content\n",
        "!git clone --quiet https://github.com/tensorflow/models.git\n",
        "\n",
        "!apt-get install -qq protobuf-compiler python-pil python-lxml python-tk\n",
        "\n",
        "!pip install -q Cython contextlib2 pillow lxml matplotlib pycocotools tf_slim\n",
        "\n",
        "%cd /content/models/research\n",
        "!protoc object_detection/protos/*.proto --python_out=.\n",
        "\n",
        "import os\n",
        "os.environ['PYTHONPATH'] += ':/content/models/research/:/content/models/research/slim/'\n",
        "\n",
        "!python object_detection/builders/model_builder_test.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Selecting previously unselected package python-bs4.\n",
            "(Reading database ... 155202 files and directories currently installed.)\n",
            "Preparing to unpack .../0-python-bs4_4.6.0-1_all.deb ...\n",
            "Unpacking python-bs4 (4.6.0-1) ...\n",
            "Selecting previously unselected package python-pkg-resources.\n",
            "Preparing to unpack .../1-python-pkg-resources_39.0.1-2_all.deb ...\n",
            "Unpacking python-pkg-resources (39.0.1-2) ...\n",
            "Selecting previously unselected package python-chardet.\n",
            "Preparing to unpack .../2-python-chardet_3.0.4-1_all.deb ...\n",
            "Unpacking python-chardet (3.0.4-1) ...\n",
            "Selecting previously unselected package python-six.\n",
            "Preparing to unpack .../3-python-six_1.11.0-2_all.deb ...\n",
            "Unpacking python-six (1.11.0-2) ...\n",
            "Selecting previously unselected package python-webencodings.\n",
            "Preparing to unpack .../4-python-webencodings_0.5-2_all.deb ...\n",
            "Unpacking python-webencodings (0.5-2) ...\n",
            "Selecting previously unselected package python-html5lib.\n",
            "Preparing to unpack .../5-python-html5lib_0.999999999-1_all.deb ...\n",
            "Unpacking python-html5lib (0.999999999-1) ...\n",
            "Selecting previously unselected package python-lxml:amd64.\n",
            "Preparing to unpack .../6-python-lxml_4.2.1-1ubuntu0.6_amd64.deb ...\n",
            "Unpacking python-lxml:amd64 (4.2.1-1ubuntu0.6) ...\n",
            "Selecting previously unselected package python-olefile.\n",
            "Preparing to unpack .../7-python-olefile_0.45.1-1_all.deb ...\n",
            "Unpacking python-olefile (0.45.1-1) ...\n",
            "Selecting previously unselected package python-pil:amd64.\n",
            "Preparing to unpack .../8-python-pil_5.1.0-1ubuntu0.7_amd64.deb ...\n",
            "Unpacking python-pil:amd64 (5.1.0-1ubuntu0.7) ...\n",
            "Setting up python-pkg-resources (39.0.1-2) ...\n",
            "Setting up python-six (1.11.0-2) ...\n",
            "Setting up python-bs4 (4.6.0-1) ...\n",
            "Setting up python-lxml:amd64 (4.2.1-1ubuntu0.6) ...\n",
            "Setting up python-olefile (0.45.1-1) ...\n",
            "Setting up python-pil:amd64 (5.1.0-1ubuntu0.7) ...\n",
            "Setting up python-webencodings (0.5-2) ...\n",
            "Setting up python-chardet (3.0.4-1) ...\n",
            "Setting up python-html5lib (0.999999999-1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "\u001b[K     |████████████████████████████████| 352 kB 31.9 MB/s \n",
            "\u001b[?25h/content/models/research\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNfIPc5yxDOv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3afd8f64-b76e-4536-b443-8bf9abb850cc"
      },
      "source": [
        "%cd /content/tensorflow-object-detection-faster-rcnn/data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/tensorflow-object-detection-faster-rcnn/data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yb_FMcfnSbRZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f1294a2-bca3-47c2-a5b3-8343b91ae3ef"
      },
      "source": [
        "# UPDATE THIS LINK - get our data from Roboflow\n",
        "!curl -L \"https://app.roboflow.com/ds/T1aQC52yhh?key=nFrqQ754oR\" > roboflow.zip; unzip roboflow.zip; rm roboflow.zip\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   891  100   891    0     0   1822      0 --:--:-- --:--:-- --:--:--  1818\n",
            "100 64.0M  100 64.0M    0     0  46.8M      0  0:00:01  0:00:01 --:--:--  169M\n",
            "Archive:  roboflow.zip\n",
            " extracting: README.dataset.txt      \n",
            " extracting: README.roboflow.txt     \n",
            "   creating: test/\n",
            " extracting: test/celll.tfrecord     \n",
            " extracting: test/celll_label_map.pbtxt  \n",
            "   creating: train/\n",
            " extracting: train/celll.tfrecord    \n",
            " extracting: train/celll_label_map.pbtxt  \n",
            "   creating: valid/\n",
            " extracting: valid/celll.tfrecord    \n",
            " extracting: valid/celll_label_map.pbtxt  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7T58u1YP9sUW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99ca68e0-08e1-451d-c4a9-1060972711cf"
      },
      "source": [
        "%ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FYI.txt  README.dataset.txt  README.roboflow.txt  \u001b[0m\u001b[01;34mtest\u001b[0m/  \u001b[01;34mtrain\u001b[0m/  \u001b[01;34mvalid\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5qhOGaTTFsq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b1d8188-a2fa-44a4-be0a-d775fb0bff7f"
      },
      "source": [
        "# check out what we have in train\n",
        "%ls train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "celll_label_map.pbtxt  celll.tfrecord\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKnnSSBu_XXF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1933dcc-6a2f-45ae-8fea-51eca13baccf"
      },
      "source": [
        "# show what we have in test\n",
        "%ls test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "celll_label_map.pbtxt  celll.tfrecord\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgd-fzAIkZlV"
      },
      "source": [
        "# NOTE: Update these TFRecord names from \"cells\" and \"cells_label_map\" to your files!\n",
        "test_record_fname = '/content/tensorflow-object-detection-faster-rcnn/data/valid/celll.tfrecord'\n",
        "train_record_fname = '/content/tensorflow-object-detection-faster-rcnn/data/train/celll.tfrecord'\n",
        "label_map_pbtxt_fname = '/content/tensorflow-object-detection-faster-rcnn/data/train/celll_label_map.pbtxt'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCNYAaC7w6N8"
      },
      "source": [
        "## Download base model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "orDCj6ihgUMR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de6e93ae-b81a-4aa4-aa63-2c42143162f9"
      },
      "source": [
        "%cd /content/models/research\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "import glob\n",
        "import urllib.request\n",
        "import tarfile\n",
        "MODEL_FILE = MODEL + '.tar.gz'\n",
        "DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n",
        "DEST_DIR = '/content/models/research/pretrained_model'\n",
        "\n",
        "if not (os.path.exists(MODEL_FILE)):\n",
        "    urllib.request.urlretrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n",
        "\n",
        "tar = tarfile.open(MODEL_FILE)\n",
        "tar.extractall()\n",
        "tar.close()\n",
        "\n",
        "os.remove(MODEL_FILE)\n",
        "if (os.path.exists(DEST_DIR)):\n",
        "    shutil.rmtree(DEST_DIR)\n",
        "os.rename(MODEL, DEST_DIR)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/models/research\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGhvAObeiIix",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eadea1fc-7de9-47f0-c63d-450d35240439"
      },
      "source": [
        "!echo {DEST_DIR}\n",
        "!ls -alh {DEST_DIR}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/models/research/pretrained_model\n",
            "total 111M\n",
            "drwxr-xr-x  3 345018 5000 4.0K Feb  1  2018 .\n",
            "drwxr-xr-x 23 root   root 4.0K May  4 03:08 ..\n",
            "-rw-r--r--  1 345018 5000   77 Feb  1  2018 checkpoint\n",
            "-rw-r--r--  1 345018 5000  55M Feb  1  2018 frozen_inference_graph.pb\n",
            "-rw-r--r--  1 345018 5000  51M Feb  1  2018 model.ckpt.data-00000-of-00001\n",
            "-rw-r--r--  1 345018 5000  16K Feb  1  2018 model.ckpt.index\n",
            "-rw-r--r--  1 345018 5000 5.5M Feb  1  2018 model.ckpt.meta\n",
            "-rw-r--r--  1 345018 5000 3.2K Feb  1  2018 pipeline.config\n",
            "drwxr-xr-x  3 345018 5000 4.0K Feb  1  2018 saved_model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHnxlfRznPP3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "28fe58d3-76e4-4efb-9d40-339a4f6fc494"
      },
      "source": [
        "fine_tune_checkpoint = os.path.join(DEST_DIR, \"model.ckpt\")\n",
        "fine_tune_checkpoint"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/models/research/pretrained_model/model.ckpt'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvwtHlLOeRJD"
      },
      "source": [
        "## Configuring a Training Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dIhw7IdpLuiU"
      },
      "source": [
        "import os\n",
        "pipeline_fname = os.path.join('/content/models/research/object_detection/samples/configs/', pipeline_file)\n",
        "\n",
        "assert os.path.isfile(pipeline_fname), '`{}` not exist'.format(pipeline_fname)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fG1nCNpUXcRU"
      },
      "source": [
        "def get_num_classes(pbtxt_fname):\n",
        "    from object_detection.utils import label_map_util\n",
        "    label_map = label_map_util.load_labelmap(pbtxt_fname)\n",
        "    categories = label_map_util.convert_label_map_to_categories(\n",
        "        label_map, max_num_classes=90, use_display_name=True)\n",
        "    category_index = label_map_util.create_category_index(categories)\n",
        "    return len(category_index.keys())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjtCbLF2i0wI"
      },
      "source": [
        "import re\n",
        "\n",
        "num_classes = get_num_classes(label_map_pbtxt_fname)\n",
        "with open(pipeline_fname) as f:\n",
        "    s = f.read()\n",
        "with open(pipeline_fname, 'w') as f:\n",
        "    \n",
        "    # fine_tune_checkpoint\n",
        "    s = re.sub('fine_tune_checkpoint: \".*?\"',\n",
        "               'fine_tune_checkpoint: \"{}\"'.format(fine_tune_checkpoint), s)\n",
        "    \n",
        "    # tfrecord files train and test.\n",
        "    s = re.sub(\n",
        "        '(input_path: \".*?)(train.record)(.*?\")', 'input_path: \"{}\"'.format(train_record_fname), s)\n",
        "    s = re.sub(\n",
        "        '(input_path: \".*?)(val.record)(.*?\")', 'input_path: \"{}\"'.format(test_record_fname), s)\n",
        "\n",
        "    # label_map_path\n",
        "    s = re.sub(\n",
        "        'label_map_path: \".*?\"', 'label_map_path: \"{}\"'.format(label_map_pbtxt_fname), s)\n",
        "\n",
        "    # Set training batch_size.\n",
        "    s = re.sub('batch_size: [0-9]+',\n",
        "               'batch_size: {}'.format(batch_size), s)\n",
        "\n",
        "    # Set training steps, num_steps\n",
        "    s = re.sub('num_steps: [0-9]+',\n",
        "               'num_steps: {}'.format(num_steps), s)\n",
        "    \n",
        "    # Set number of classes num_classes.\n",
        "    s = re.sub('num_classes: [0-9]+',\n",
        "               'num_classes: {}'.format(num_classes), s)\n",
        "    f.write(s)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GH0MEEanocn6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0268f43-b165-40db-be61-b64a791d7d7c"
      },
      "source": [
        "!cat {pipeline_fname}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# Faster R-CNN with Inception v2, configured for Oxford-IIIT Pets Dataset.\n",
            "# Users should configure the fine_tune_checkpoint field in the train config as\n",
            "# well as the label_map_path and input_path fields in the train_input_reader and\n",
            "# eval_input_reader. Search for \"PATH_TO_BE_CONFIGURED\" to find the fields that\n",
            "# should be configured.\n",
            "\n",
            "model {\n",
            "  faster_rcnn {\n",
            "    num_classes: 3\n",
            "    image_resizer {\n",
            "      keep_aspect_ratio_resizer {\n",
            "        min_dimension: 600\n",
            "        max_dimension: 1024\n",
            "      }\n",
            "    }\n",
            "    feature_extractor {\n",
            "      type: 'faster_rcnn_inception_v2'\n",
            "      first_stage_features_stride: 16\n",
            "    }\n",
            "    first_stage_anchor_generator {\n",
            "      grid_anchor_generator {\n",
            "        scales: [0.25, 0.5, 1.0, 2.0]\n",
            "        aspect_ratios: [0.5, 1.0, 2.0]\n",
            "        height_stride: 16\n",
            "        width_stride: 16\n",
            "      }\n",
            "    }\n",
            "    first_stage_box_predictor_conv_hyperparams {\n",
            "      op: CONV\n",
            "      regularizer {\n",
            "        l2_regularizer {\n",
            "          weight: 0.0\n",
            "        }\n",
            "      }\n",
            "      initializer {\n",
            "        truncated_normal_initializer {\n",
            "          stddev: 0.01\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "    first_stage_nms_score_threshold: 0.0\n",
            "    first_stage_nms_iou_threshold: 0.7\n",
            "    first_stage_max_proposals: 300\n",
            "    first_stage_localization_loss_weight: 2.0\n",
            "    first_stage_objectness_loss_weight: 1.0\n",
            "    initial_crop_size: 14\n",
            "    maxpool_kernel_size: 2\n",
            "    maxpool_stride: 2\n",
            "    second_stage_box_predictor {\n",
            "      mask_rcnn_box_predictor {\n",
            "        use_dropout: false\n",
            "        dropout_keep_probability: 1.0\n",
            "        fc_hyperparams {\n",
            "          op: FC\n",
            "          regularizer {\n",
            "            l2_regularizer {\n",
            "              weight: 0.0\n",
            "            }\n",
            "          }\n",
            "          initializer {\n",
            "            variance_scaling_initializer {\n",
            "              factor: 1.0\n",
            "              uniform: true\n",
            "              mode: FAN_AVG\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "    second_stage_post_processing {\n",
            "      batch_non_max_suppression {\n",
            "        score_threshold: 0.0\n",
            "        iou_threshold: 0.6\n",
            "        max_detections_per_class: 100\n",
            "        max_total_detections: 300\n",
            "      }\n",
            "      score_converter: SOFTMAX\n",
            "    }\n",
            "    second_stage_localization_loss_weight: 2.0\n",
            "    second_stage_classification_loss_weight: 1.0\n",
            "  }\n",
            "}\n",
            "\n",
            "train_config: {\n",
            "  batch_size: 1\n",
            "  optimizer {\n",
            "    momentum_optimizer: {\n",
            "      learning_rate: {\n",
            "        manual_step_learning_rate {\n",
            "          initial_learning_rate: 0.0002\n",
            "          schedule {\n",
            "            step: 900000\n",
            "            learning_rate: .00002\n",
            "          }\n",
            "          schedule {\n",
            "            step: 1200000\n",
            "            learning_rate: .000002\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "      momentum_optimizer_value: 0.9\n",
            "    }\n",
            "    use_moving_average: false\n",
            "  }\n",
            "  gradient_clipping_by_norm: 10.0\n",
            "  fine_tune_checkpoint: \"/content/models/research/pretrained_model/model.ckpt\"\n",
            "  from_detection_checkpoint: true\n",
            "  load_all_detection_checkpoint_vars: true\n",
            "  # Note: The below line limits the training process to 200K steps, which we\n",
            "  # empirically found to be sufficient enough to train the pets dataset. This\n",
            "  # effectively bypasses the learning rate schedule (the learning rate will\n",
            "  # never decay). Remove the below line to train indefinitely.\n",
            "  num_steps: 10000\n",
            "  data_augmentation_options {\n",
            "    random_horizontal_flip {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "\n",
            "train_input_reader: {\n",
            "  tf_record_input_reader {\n",
            "    input_path: \"/content/tensorflow-object-detection-faster-rcnn/data/train/celll.tfrecord\"\n",
            "  }\n",
            "  label_map_path: \"/content/tensorflow-object-detection-faster-rcnn/data/train/celll_label_map.pbtxt\"\n",
            "}\n",
            "\n",
            "eval_config: {\n",
            "  metrics_set: \"coco_detection_metrics\"\n",
            "  num_examples: 1101\n",
            "}\n",
            "\n",
            "eval_input_reader: {\n",
            "  tf_record_input_reader {\n",
            "    input_path: \"/content/tensorflow-object-detection-faster-rcnn/data/valid/celll.tfrecord\"\n",
            "  }\n",
            "  label_map_path: \"/content/tensorflow-object-detection-faster-rcnn/data/train/celll_label_map.pbtxt\"\n",
            "  shuffle: false\n",
            "  num_readers: 1\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f11w0uO3jFCB"
      },
      "source": [
        "model_dir = 'training/'\n",
        "# Optionally remove content in output model directory to fresh start.\n",
        "!rm -rf {model_dir}\n",
        "os.makedirs(model_dir, exist_ok=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23TECXvNezIF"
      },
      "source": [
        "## Run Tensorboard(Optional)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0H2PZs-mSCmO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9eaac60a-c52b-4d2c-87d2-66c95a710011"
      },
      "source": [
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip -o ngrok-stable-linux-amd64.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-05-04 03:09:02--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 54.161.241.46, 54.237.133.81, 18.205.222.128, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|54.161.241.46|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13832437 (13M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.zip’\n",
            "\n",
            "ngrok-stable-linux- 100%[===================>]  13.19M  3.29MB/s    in 5.0s    \n",
            "\n",
            "2022-05-04 03:09:08 (2.62 MB/s) - ‘ngrok-stable-linux-amd64.zip’ saved [13832437/13832437]\n",
            "\n",
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "  inflating: ngrok                   \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8o6r1o5SC5M"
      },
      "source": [
        "LOG_DIR = model_dir\n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(LOG_DIR)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ge1OX7gcSC7S"
      },
      "source": [
        "get_ipython().system_raw('./ngrok http 6006 &')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5GSGxZNh8rp"
      },
      "source": [
        "### Get Tensorboard link"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjhPT9iPSJ6T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b3f5dcd-307e-41ab-8e8e-511f7c2854fc"
      },
      "source": [
        "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://df57-35-233-231-78.ngrok.io\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JDddx2rPfex9"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nC7_syR1SJ9F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "519a4ea4-a9f3-4297-9a5d-22a8c3247599"
      },
      "source": [
        "!pip install lvis"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting lvis\n",
            "  Downloading lvis-0.5.3-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from lvis) (1.15.0)\n",
            "Requirement already satisfied: Cython>=0.29.12 in /usr/local/lib/python3.7/dist-packages (from lvis) (0.29.28)\n",
            "Requirement already satisfied: pyparsing>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from lvis) (3.0.8)\n",
            "Requirement already satisfied: numpy>=1.18.2 in /usr/local/lib/python3.7/dist-packages (from lvis) (1.19.5)\n",
            "Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.7/dist-packages (from lvis) (4.1.2.30)\n",
            "Requirement already satisfied: kiwisolver>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from lvis) (1.4.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.7/dist-packages (from lvis) (2.8.2)\n",
            "Requirement already satisfied: matplotlib>=3.1.1 in /usr/local/lib/python3.7/dist-packages (from lvis) (3.2.2)\n",
            "Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from lvis) (0.11.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.1.0->lvis) (4.2.0)\n",
            "Installing collected packages: lvis\n",
            "Successfully installed lvis-0.5.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjDHjhKQofT5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fed78a0e-ee18-425e-fd0d-0abeae5c5697"
      },
      "source": [
        "!python /content/models/research/object_detection/model_main.py \\\n",
        "    --pipeline_config_path={pipeline_fname} \\\n",
        "    --model_dir={model_dir} \\\n",
        "    --alsologtostderr \\\n",
        "    --num_train_steps={num_steps} \\\n",
        "    --num_eval_steps={num_eval_steps}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.\n",
            "W0504 03:09:25.248539 140467053463424 model_lib.py:839] Forced number of epochs for all eval validations to be 1.\n",
            "INFO:tensorflow:Maybe overwriting train_steps: 10000\n",
            "I0504 03:09:25.248769 140467053463424 config_util.py:552] Maybe overwriting train_steps: 10000\n",
            "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
            "I0504 03:09:25.248862 140467053463424 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
            "INFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: 1\n",
            "I0504 03:09:25.248935 140467053463424 config_util.py:552] Maybe overwriting sample_1_of_n_eval_examples: 1\n",
            "INFO:tensorflow:Maybe overwriting eval_num_epochs: 1\n",
            "I0504 03:09:25.249009 140467053463424 config_util.py:552] Maybe overwriting eval_num_epochs: 1\n",
            "WARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
            "W0504 03:09:25.249106 140467053463424 model_lib.py:855] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
            "INFO:tensorflow:create_estimator_and_inputs: use_tpu False, export_to_tpu None\n",
            "I0504 03:09:25.249207 140467053463424 model_lib.py:892] create_estimator_and_inputs: use_tpu False, export_to_tpu None\n",
            "INFO:tensorflow:Using config: {'_model_dir': 'training/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fc0897e8450>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "I0504 03:09:25.249613 140467053463424 estimator.py:212] Using config: {'_model_dir': 'training/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fc0897e8450>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "WARNING:tensorflow:Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7fc084946ef0>) includes params argument, but params are not passed to Estimator.\n",
            "W0504 03:09:25.249831 140467053463424 model_fn.py:630] Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7fc084946ef0>) includes params argument, but params are not passed to Estimator.\n",
            "INFO:tensorflow:Not using Distribute Coordinator.\n",
            "I0504 03:09:25.250238 140467053463424 estimator_training.py:186] Not using Distribute Coordinator.\n",
            "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
            "I0504 03:09:25.250409 140467053463424 training.py:612] Running training and evaluation locally (non-distributed).\n",
            "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
            "I0504 03:09:25.250627 140467053463424 training.py:700] Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "W0504 03:09:25.254858 140467053463424 deprecation.py:323] From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/tensorflow-object-detection-faster-rcnn/data/train/celll.tfrecord']\n",
            "I0504 03:09:25.275526 140467053463424 dataset_builder.py:162] Reading unweighted datasets: ['/content/tensorflow-object-detection-faster-rcnn/data/train/celll.tfrecord']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/tensorflow-object-detection-faster-rcnn/data/train/celll.tfrecord']\n",
            "I0504 03:09:25.276103 140467053463424 dataset_builder.py:79] Reading record datasets for input file: ['/content/tensorflow-object-detection-faster-rcnn/data/train/celll.tfrecord']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I0504 03:09:25.276250 140467053463424 dataset_builder.py:80] Number of filenames to read: 1\n",
            "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
            "W0504 03:09:25.276340 140467053463424 dataset_builder.py:87] num_readers has been reduced to 1 to match input file shards.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:104: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
            "W0504 03:09:25.281085 140467053463424 deprecation.py:323] From /content/models/research/object_detection/builders/dataset_builder.py:104: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "W0504 03:09:25.298252 140467053463424 deprecation.py:323] From /content/models/research/object_detection/builders/dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/inputs.py:113: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0504 03:09:44.074618 140467053463424 deprecation.py:323] From /content/models/research/object_detection/inputs.py:113: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/inputs.py:97: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "W0504 03:09:44.233788 140467053463424 deprecation.py:323] From /content/models/research/object_detection/inputs.py:97: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/inputs.py:288: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0504 03:09:49.150133 140467053463424 deprecation.py:323] From /content/models/research/object_detection/inputs.py:288: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0504 03:09:53.585125 140467053463424 estimator.py:1148] Calling model_fn.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tf_slim/layers/layers.py:2802: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "W0504 03:09:53.616915 140467053463424 deprecation.py:323] From /usr/local/lib/python3.7/dist-packages/tf_slim/layers/layers.py:2802: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0504 03:09:54.953113 140467053463424 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0504 03:09:55.077460 140467053463424 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0504 03:09:55.077902 140467053463424 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/utils/spatial_transform_ops.py:479: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "box_ind is deprecated, use box_indices instead\n",
            "W0504 03:09:55.781764 140467053463424 deprecation.py:506] From /content/models/research/object_detection/utils/spatial_transform_ops.py:479: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "box_ind is deprecated, use box_indices instead\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tf_slim/layers/layers.py:1666: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.flatten instead.\n",
            "W0504 03:09:56.262421 140467053463424 deprecation.py:323] From /usr/local/lib/python3.7/dist-packages/tf_slim/layers/layers.py:1666: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.flatten instead.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0504 03:09:56.264610 140467053463424 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0504 03:09:56.280173 140467053463424 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/core/losses.py:461: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n",
            "W0504 03:09:56.567075 140467053463424 deprecation.py:323] From /content/models/research/object_detection/core/losses.py:461: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0504 03:10:00.261172 140467053463424 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "I0504 03:10:00.262611 140467053463424 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0504 03:10:02.040041 140467053463424 monitored_session.py:240] Graph was finalized.\n",
            "2022-05-04 03:10:02.040462: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
            "2022-05-04 03:10:02.044956: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2199995000 Hz\n",
            "2022-05-04 03:10:02.045160: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0xef89340 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2022-05-04 03:10:02.045202: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2022-05-04 03:10:02.046980: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2022-05-04 03:10:02.322210: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-05-04 03:10:02.322898: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0xef88fc0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2022-05-04 03:10:02.322931: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2022-05-04 03:10:02.324172: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-05-04 03:10:02.324699: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2022-05-04 03:10:02.336881: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2022-05-04 03:10:02.498255: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2022-05-04 03:10:02.572467: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2022-05-04 03:10:02.593396: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2022-05-04 03:10:02.780989: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2022-05-04 03:10:02.890658: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2022-05-04 03:10:03.249503: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2022-05-04 03:10:03.249723: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-05-04 03:10:03.250414: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-05-04 03:10:03.250926: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2022-05-04 03:10:03.251034: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2022-05-04 03:10:03.252467: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2022-05-04 03:10:03.252501: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2022-05-04 03:10:03.252512: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2022-05-04 03:10:03.252703: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-05-04 03:10:03.253269: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-05-04 03:10:03.253823: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2022-05-04 03:10:03.253866: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14257 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0504 03:10:05.331627 140467053463424 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0504 03:10:05.477765 140467053463424 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into training/model.ckpt.\n",
            "I0504 03:10:09.876302 140467053463424 basic_session_run_hooks.py:606] Saving checkpoints for 0 into training/model.ckpt.\n",
            "2022-05-04 03:10:13.728678: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2022-05-04 03:10:14.553977: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "INFO:tensorflow:loss = 5.1388187, step = 0\n",
            "I0504 03:10:21.468912 140467053463424 basic_session_run_hooks.py:262] loss = 5.1388187, step = 0\n",
            "INFO:tensorflow:global_step/sec: 1.28595\n",
            "I0504 03:11:39.231675 140467053463424 basic_session_run_hooks.py:692] global_step/sec: 1.28595\n",
            "INFO:tensorflow:loss = 1.3375751, step = 100 (77.764 sec)\n",
            "I0504 03:11:39.232774 140467053463424 basic_session_run_hooks.py:260] loss = 1.3375751, step = 100 (77.764 sec)\n",
            "INFO:tensorflow:global_step/sec: 4.2776\n",
            "I0504 03:12:02.609240 140467053463424 basic_session_run_hooks.py:692] global_step/sec: 4.2776\n",
            "INFO:tensorflow:loss = 1.1461521, step = 200 (23.378 sec)\n",
            "I0504 03:12:02.610502 140467053463424 basic_session_run_hooks.py:260] loss = 1.1461521, step = 200 (23.378 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.77699\n",
            "I0504 03:12:29.085382 140467053463424 basic_session_run_hooks.py:692] global_step/sec: 3.77699\n",
            "INFO:tensorflow:loss = 3.1242986, step = 300 (26.476 sec)\n",
            "I0504 03:12:29.086574 140467053463424 basic_session_run_hooks.py:260] loss = 3.1242986, step = 300 (26.476 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.83896\n",
            "I0504 03:12:55.134048 140467053463424 basic_session_run_hooks.py:692] global_step/sec: 3.83896\n",
            "INFO:tensorflow:loss = 1.7611567, step = 400 (26.048 sec)\n",
            "I0504 03:12:55.135066 140467053463424 basic_session_run_hooks.py:260] loss = 1.7611567, step = 400 (26.048 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.05121\n",
            "I0504 03:13:06.182327 140467053463424 basic_session_run_hooks.py:692] global_step/sec: 9.05121\n",
            "INFO:tensorflow:loss = 3.2090387, step = 500 (11.048 sec)\n",
            "I0504 03:13:06.183255 140467053463424 basic_session_run_hooks.py:260] loss = 3.2090387, step = 500 (11.048 sec)\n",
            "INFO:tensorflow:global_step/sec: 6.0505\n",
            "I0504 03:13:22.709835 140467053463424 basic_session_run_hooks.py:692] global_step/sec: 6.0505\n",
            "INFO:tensorflow:loss = 1.3408403, step = 600 (16.528 sec)\n",
            "I0504 03:13:22.711000 140467053463424 basic_session_run_hooks.py:260] loss = 1.3408403, step = 600 (16.528 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.85488\n",
            "I0504 03:13:39.789616 140467053463424 basic_session_run_hooks.py:692] global_step/sec: 5.85488\n",
            "INFO:tensorflow:loss = 0.7803378, step = 700 (17.080 sec)\n",
            "I0504 03:13:39.790747 140467053463424 basic_session_run_hooks.py:260] loss = 0.7803378, step = 700 (17.080 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.83638\n",
            "I0504 03:13:49.955948 140467053463424 basic_session_run_hooks.py:692] global_step/sec: 9.83638\n",
            "INFO:tensorflow:loss = 2.6489482, step = 800 (10.166 sec)\n",
            "I0504 03:13:49.957062 140467053463424 basic_session_run_hooks.py:260] loss = 2.6489482, step = 800 (10.166 sec)\n",
            "INFO:tensorflow:global_step/sec: 8.25382\n",
            "I0504 03:14:02.071548 140467053463424 basic_session_run_hooks.py:692] global_step/sec: 8.25382\n",
            "INFO:tensorflow:loss = 2.1524262, step = 900 (12.116 sec)\n",
            "I0504 03:14:02.072588 140467053463424 basic_session_run_hooks.py:260] loss = 2.1524262, step = 900 (12.116 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.87622\n",
            "I0504 03:14:12.196863 140467053463424 basic_session_run_hooks.py:692] global_step/sec: 9.87622\n",
            "INFO:tensorflow:loss = 1.6838242, step = 1000 (10.126 sec)\n",
            "I0504 03:14:12.198109 140467053463424 basic_session_run_hooks.py:260] loss = 1.6838242, step = 1000 (10.126 sec)\n",
            "INFO:tensorflow:global_step/sec: 10.2219\n",
            "I0504 03:14:21.979798 140467053463424 basic_session_run_hooks.py:692] global_step/sec: 10.2219\n",
            "INFO:tensorflow:loss = 1.282421, step = 1100 (9.783 sec)\n",
            "I0504 03:14:21.980802 140467053463424 basic_session_run_hooks.py:260] loss = 1.282421, step = 1100 (9.783 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.77287\n",
            "I0504 03:14:32.212195 140467053463424 basic_session_run_hooks.py:692] global_step/sec: 9.77287\n",
            "INFO:tensorflow:loss = 1.2513785, step = 1200 (10.233 sec)\n",
            "I0504 03:14:32.213348 140467053463424 basic_session_run_hooks.py:260] loss = 1.2513785, step = 1200 (10.233 sec)\n",
            "INFO:tensorflow:global_step/sec: 10.2466\n",
            "I0504 03:14:41.971501 140467053463424 basic_session_run_hooks.py:692] global_step/sec: 10.2466\n",
            "INFO:tensorflow:loss = 1.7861558, step = 1300 (9.759 sec)\n",
            "I0504 03:14:41.972543 140467053463424 basic_session_run_hooks.py:260] loss = 1.7861558, step = 1300 (9.759 sec)\n",
            "INFO:tensorflow:global_step/sec: 10.2218\n",
            "I0504 03:14:51.754521 140467053463424 basic_session_run_hooks.py:692] global_step/sec: 10.2218\n",
            "INFO:tensorflow:loss = 1.2277725, step = 1400 (9.783 sec)\n",
            "I0504 03:14:51.755455 140467053463424 basic_session_run_hooks.py:260] loss = 1.2277725, step = 1400 (9.783 sec)\n",
            "INFO:tensorflow:global_step/sec: 10.3953\n",
            "I0504 03:15:01.374304 140467053463424 basic_session_run_hooks.py:692] global_step/sec: 10.3953\n",
            "INFO:tensorflow:loss = 0.8982067, step = 1500 (9.620 sec)\n",
            "I0504 03:15:01.375384 140467053463424 basic_session_run_hooks.py:260] loss = 0.8982067, step = 1500 (9.620 sec)\n",
            "INFO:tensorflow:global_step/sec: 10.2054\n",
            "I0504 03:15:11.173083 140467053463424 basic_session_run_hooks.py:692] global_step/sec: 10.2054\n",
            "INFO:tensorflow:loss = 0.55747986, step = 1600 (9.799 sec)\n",
            "I0504 03:15:11.174110 140467053463424 basic_session_run_hooks.py:260] loss = 0.55747986, step = 1600 (9.799 sec)\n",
            "INFO:tensorflow:global_step/sec: 10.1939\n",
            "I0504 03:15:20.982887 140467053463424 basic_session_run_hooks.py:692] global_step/sec: 10.1939\n",
            "INFO:tensorflow:loss = 2.3505561, step = 1700 (9.810 sec)\n",
            "I0504 03:15:20.984020 140467053463424 basic_session_run_hooks.py:260] loss = 2.3505561, step = 1700 (9.810 sec)\n",
            "INFO:tensorflow:global_step/sec: 10.3059\n",
            "I0504 03:15:30.686063 140467053463424 basic_session_run_hooks.py:692] global_step/sec: 10.3059\n",
            "INFO:tensorflow:loss = 4.2407827, step = 1800 (9.703 sec)\n",
            "I0504 03:15:30.687052 140467053463424 basic_session_run_hooks.py:260] loss = 4.2407827, step = 1800 (9.703 sec)\n",
            "INFO:tensorflow:global_step/sec: 10.3348\n",
            "I0504 03:15:40.362100 140467053463424 basic_session_run_hooks.py:692] global_step/sec: 10.3348\n",
            "INFO:tensorflow:loss = 2.7845266, step = 1900 (9.676 sec)\n",
            "I0504 03:15:40.362938 140467053463424 basic_session_run_hooks.py:260] loss = 2.7845266, step = 1900 (9.676 sec)\n",
            "INFO:tensorflow:global_step/sec: 10.2837\n",
            "I0504 03:15:50.086277 140467053463424 basic_session_run_hooks.py:692] global_step/sec: 10.2837\n",
            "INFO:tensorflow:loss = 1.3518865, step = 2000 (9.724 sec)\n",
            "I0504 03:15:50.087135 140467053463424 basic_session_run_hooks.py:260] loss = 1.3518865, step = 2000 (9.724 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.85648\n",
            "I0504 03:16:00.231845 140467053463424 basic_session_run_hooks.py:692] global_step/sec: 9.85648\n",
            "INFO:tensorflow:loss = 1.9661614, step = 2100 (10.146 sec)\n",
            "I0504 03:16:00.232883 140467053463424 basic_session_run_hooks.py:260] loss = 1.9661614, step = 2100 (10.146 sec)\n",
            "INFO:tensorflow:global_step/sec: 10.2406\n",
            "I0504 03:16:09.996947 140467053463424 basic_session_run_hooks.py:692] global_step/sec: 10.2406\n",
            "INFO:tensorflow:loss = 3.2660513, step = 2200 (9.765 sec)\n",
            "I0504 03:16:09.998118 140467053463424 basic_session_run_hooks.py:260] loss = 3.2660513, step = 2200 (9.765 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.92807\n",
            "I0504 03:16:20.069365 140467053463424 basic_session_run_hooks.py:692] global_step/sec: 9.92807\n",
            "INFO:tensorflow:loss = 2.9798503, step = 2300 (10.072 sec)\n",
            "I0504 03:16:20.070528 140467053463424 basic_session_run_hooks.py:260] loss = 2.9798503, step = 2300 (10.072 sec)\n",
            "INFO:tensorflow:global_step/sec: 10.3425\n",
            "I0504 03:16:29.738233 140467053463424 basic_session_run_hooks.py:692] global_step/sec: 10.3425\n",
            "INFO:tensorflow:loss = 1.245148, step = 2400 (9.669 sec)\n",
            "I0504 03:16:29.739451 140467053463424 basic_session_run_hooks.py:260] loss = 1.245148, step = 2400 (9.669 sec)\n",
            "INFO:tensorflow:global_step/sec: 10.2033\n",
            "I0504 03:16:39.538920 140467053463424 basic_session_run_hooks.py:692] global_step/sec: 10.2033\n",
            "INFO:tensorflow:loss = 1.9895489, step = 2500 (9.801 sec)\n",
            "I0504 03:16:39.540048 140467053463424 basic_session_run_hooks.py:260] loss = 1.9895489, step = 2500 (9.801 sec)\n",
            "INFO:tensorflow:global_step/sec: 10.2715\n",
            "I0504 03:16:49.274577 140467053463424 basic_session_run_hooks.py:692] global_step/sec: 10.2715\n",
            "INFO:tensorflow:loss = 2.1902752, step = 2600 (9.736 sec)\n",
            "I0504 03:16:49.275674 140467053463424 basic_session_run_hooks.py:260] loss = 2.1902752, step = 2600 (9.736 sec)\n",
            "INFO:tensorflow:global_step/sec: 10.3571\n",
            "I0504 03:16:58.929891 140467053463424 basic_session_run_hooks.py:692] global_step/sec: 10.3571\n",
            "INFO:tensorflow:loss = 1.2723116, step = 2700 (9.655 sec)\n",
            "I0504 03:16:58.931121 140467053463424 basic_session_run_hooks.py:260] loss = 1.2723116, step = 2700 (9.655 sec)\n",
            "INFO:tensorflow:global_step/sec: 10.2914\n",
            "I0504 03:17:08.646662 140467053463424 basic_session_run_hooks.py:692] global_step/sec: 10.2914\n",
            "INFO:tensorflow:loss = 2.86548, step = 2800 (9.717 sec)\n",
            "I0504 03:17:08.647679 140467053463424 basic_session_run_hooks.py:260] loss = 2.86548, step = 2800 (9.717 sec)\n",
            "INFO:tensorflow:global_step/sec: 10.2812\n",
            "I0504 03:17:18.373165 140467053463424 basic_session_run_hooks.py:692] global_step/sec: 10.2812\n",
            "INFO:tensorflow:loss = 0.8772249, step = 2900 (9.728 sec)\n",
            "I0504 03:17:18.375284 140467053463424 basic_session_run_hooks.py:260] loss = 0.8772249, step = 2900 (9.728 sec)\n",
            "INFO:tensorflow:global_step/sec: 10.2368\n",
            "I0504 03:17:28.141835 140467053463424 basic_session_run_hooks.py:692] global_step/sec: 10.2368\n",
            "INFO:tensorflow:loss = 0.9842217, step = 3000 (9.768 sec)\n",
            "I0504 03:17:28.142830 140467053463424 basic_session_run_hooks.py:260] loss = 0.9842217, step = 3000 (9.768 sec)\n",
            "INFO:tensorflow:global_step/sec: 10.3363\n",
            "I0504 03:17:37.816462 140467053463424 basic_session_run_hooks.py:692] global_step/sec: 10.3363\n",
            "INFO:tensorflow:loss = 2.7523725, step = 3100 (9.675 sec)\n",
            "I0504 03:17:37.817386 140467053463424 basic_session_run_hooks.py:260] loss = 2.7523725, step = 3100 (9.675 sec)\n",
            "INFO:tensorflow:global_step/sec: 10.3076\n",
            "I0504 03:17:47.518012 140467053463424 basic_session_run_hooks.py:692] global_step/sec: 10.3076\n",
            "INFO:tensorflow:loss = 3.142424, step = 3200 (9.702 sec)\n",
            "I0504 03:17:47.519124 140467053463424 basic_session_run_hooks.py:260] loss = 3.142424, step = 3200 (9.702 sec)\n",
            "INFO:tensorflow:global_step/sec: 10.2337\n",
            "I0504 03:17:57.289614 140467053463424 basic_session_run_hooks.py:692] global_step/sec: 10.2337\n",
            "INFO:tensorflow:loss = 1.9573872, step = 3300 (9.771 sec)\n",
            "I0504 03:17:57.290590 140467053463424 basic_session_run_hooks.py:260] loss = 1.9573872, step = 3300 (9.771 sec)\n",
            "INFO:tensorflow:global_step/sec: 10.2956\n",
            "I0504 03:18:07.002485 140467053463424 basic_session_run_hooks.py:692] global_step/sec: 10.2956\n",
            "INFO:tensorflow:loss = 0.91733325, step = 3400 (9.713 sec)\n",
            "I0504 03:18:07.003399 140467053463424 basic_session_run_hooks.py:260] loss = 0.91733325, step = 3400 (9.713 sec)\n",
            "INFO:tensorflow:global_step/sec: 10.2716\n",
            "I0504 03:18:16.738100 140467053463424 basic_session_run_hooks.py:692] global_step/sec: 10.2716\n",
            "INFO:tensorflow:loss = 3.4991097, step = 3500 (9.736 sec)\n",
            "I0504 03:18:16.739118 140467053463424 basic_session_run_hooks.py:260] loss = 3.4991097, step = 3500 (9.736 sec)\n",
            "INFO:tensorflow:global_step/sec: 10.2317\n",
            "I0504 03:18:36.221073 140467053463424 basic_session_run_hooks.py:692] global_step/sec: 10.2317\n",
            "INFO:tensorflow:loss = 1.4724973, step = 3700 (9.773 sec)\n",
            "I0504 03:18:36.222038 140467053463424 basic_session_run_hooks.py:260] loss = 1.4724973, step = 3700 (9.773 sec)\n",
            "INFO:tensorflow:global_step/sec: 10.2278\n",
            "I0504 03:18:45.998369 140467053463424 basic_session_run_hooks.py:692] global_step/sec: 10.2278\n",
            "INFO:tensorflow:loss = 0.7702601, step = 3800 (9.778 sec)\n",
            "I0504 03:18:45.999578 140467053463424 basic_session_run_hooks.py:260] loss = 0.7702601, step = 3800 (9.778 sec)\n",
            "INFO:tensorflow:global_step/sec: 10.31\n",
            "I0504 03:18:55.697668 140467053463424 basic_session_run_hooks.py:692] global_step/sec: 10.31\n",
            "INFO:tensorflow:loss = 0.50892496, step = 3900 (9.699 sec)\n",
            "I0504 03:18:55.698521 140467053463424 basic_session_run_hooks.py:260] loss = 0.50892496, step = 3900 (9.699 sec)\n",
            "INFO:tensorflow:global_step/sec: 10.3129\n",
            "I0504 03:19:05.394291 140467053463424 basic_session_run_hooks.py:692] global_step/sec: 10.3129\n",
            "INFO:tensorflow:loss = 3.1657877, step = 4000 (9.697 sec)\n",
            "I0504 03:19:05.395417 140467053463424 basic_session_run_hooks.py:260] loss = 3.1657877, step = 4000 (9.697 sec)\n",
            "INFO:tensorflow:global_step/sec: 10.3191\n",
            "I0504 03:19:15.084986 140467053463424 basic_session_run_hooks.py:692] global_step/sec: 10.3191\n",
            "INFO:tensorflow:loss = 2.0865948, step = 4100 (9.691 sec)\n",
            "I0504 03:19:15.086117 140467053463424 basic_session_run_hooks.py:260] loss = 2.0865948, step = 4100 (9.691 sec)\n",
            "INFO:tensorflow:global_step/sec: 10.0663\n",
            "I0504 03:19:25.019141 140467053463424 basic_session_run_hooks.py:692] global_step/sec: 10.0663\n",
            "INFO:tensorflow:loss = 1.0203288, step = 4200 (9.934 sec)\n",
            "I0504 03:19:25.020198 140467053463424 basic_session_run_hooks.py:260] loss = 1.0203288, step = 4200 (9.934 sec)\n",
            "INFO:tensorflow:global_step/sec: 10.2482\n",
            "I0504 03:19:34.776985 140467053463424 basic_session_run_hooks.py:692] global_step/sec: 10.2482\n",
            "INFO:tensorflow:loss = 1.2422136, step = 4300 (9.758 sec)\n",
            "I0504 03:19:34.778105 140467053463424 basic_session_run_hooks.py:260] loss = 1.2422136, step = 4300 (9.758 sec)\n",
            "INFO:tensorflow:global_step/sec: 10.3255\n",
            "I0504 03:19:44.461730 140467053463424 basic_session_run_hooks.py:692] global_step/sec: 10.3255\n",
            "INFO:tensorflow:loss = 1.4189236, step = 4400 (9.686 sec)\n",
            "I0504 03:19:44.464539 140467053463424 basic_session_run_hooks.py:260] loss = 1.4189236, step = 4400 (9.686 sec)\n",
            "INFO:tensorflow:global_step/sec: 10.232\n",
            "I0504 03:19:54.235043 140467053463424 basic_session_run_hooks.py:692] global_step/sec: 10.232\n",
            "INFO:tensorflow:loss = 3.1126873, step = 4500 (9.771 sec)\n",
            "I0504 03:19:54.236009 140467053463424 basic_session_run_hooks.py:260] loss = 3.1126873, step = 4500 (9.771 sec)\n",
            "INFO:tensorflow:global_step/sec: 10.2741\n",
            "I0504 03:20:03.968208 140467053463424 basic_session_run_hooks.py:692] global_step/sec: 10.2741\n",
            "INFO:tensorflow:loss = 0.9421227, step = 4600 (9.733 sec)\n",
            "I0504 03:20:03.969036 140467053463424 basic_session_run_hooks.py:260] loss = 0.9421227, step = 4600 (9.733 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 4675 into training/model.ckpt.\n",
            "I0504 03:20:11.168081 140467053463424 basic_session_run_hooks.py:606] Saving checkpoints for 4675 into training/model.ckpt.\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/tensorflow-object-detection-faster-rcnn/data/valid/celll.tfrecord']\n",
            "I0504 03:20:12.048736 140467053463424 dataset_builder.py:162] Reading unweighted datasets: ['/content/tensorflow-object-detection-faster-rcnn/data/valid/celll.tfrecord']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/tensorflow-object-detection-faster-rcnn/data/valid/celll.tfrecord']\n",
            "I0504 03:20:12.049367 140467053463424 dataset_builder.py:79] Reading record datasets for input file: ['/content/tensorflow-object-detection-faster-rcnn/data/valid/celll.tfrecord']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I0504 03:20:12.049505 140467053463424 dataset_builder.py:80] Number of filenames to read: 1\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0504 03:20:13.024158 140467053463424 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0504 03:20:14.254574 140467053463424 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0504 03:20:14.374804 140467053463424 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0504 03:20:14.375180 140467053463424 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0504 03:20:15.296375 140467053463424 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0504 03:20:15.311495 140467053463424 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/util/dispatch.py:180: batch_gather (from tensorflow.python.ops.array_ops) is deprecated and will be removed after 2017-10-25.\n",
            "Instructions for updating:\n",
            "`tf.batch_gather` is deprecated, please use `tf.gather` with `batch_dims=-1` instead.\n",
            "W0504 03:20:15.746072 140467053463424 deprecation.py:323] From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/util/dispatch.py:180: batch_gather (from tensorflow.python.ops.array_ops) is deprecated and will be removed after 2017-10-25.\n",
            "Instructions for updating:\n",
            "`tf.batch_gather` is deprecated, please use `tf.gather` with `batch_dims=-1` instead.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/eval_util.py:929: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0504 03:20:16.284091 140467053463424 deprecation.py:323] From /content/models/research/object_detection/eval_util.py:929: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/utils/visualization_utils.py:618: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "tf.py_func is deprecated in TF V2. Instead, there are two\n",
            "    options available in V2.\n",
            "    - tf.py_function takes a python function which manipulates tf eager\n",
            "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
            "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
            "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
            "    being differentiable using a gradient tape.\n",
            "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
            "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
            "    stateful argument making all functions stateful.\n",
            "    \n",
            "W0504 03:20:16.467041 140467053463424 deprecation.py:323] From /content/models/research/object_detection/utils/visualization_utils.py:618: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "tf.py_func is deprecated in TF V2. Instead, there are two\n",
            "    options available in V2.\n",
            "    - tf.py_function takes a python function which manipulates tf eager\n",
            "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
            "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
            "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
            "    being differentiable using a gradient tape.\n",
            "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
            "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
            "    stateful argument making all functions stateful.\n",
            "    \n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0504 03:20:17.197265 140467053463424 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2022-05-04T03:20:17Z\n",
            "I0504 03:20:17.212621 140467053463424 evaluation.py:255] Starting evaluation at 2022-05-04T03:20:17Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0504 03:20:17.641680 140467053463424 monitored_session.py:240] Graph was finalized.\n",
            "2022-05-04 03:20:17.642828: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-05-04 03:20:17.643221: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2022-05-04 03:20:17.643355: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2022-05-04 03:20:17.643386: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2022-05-04 03:20:17.643411: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2022-05-04 03:20:17.643434: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2022-05-04 03:20:17.643456: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2022-05-04 03:20:17.643478: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2022-05-04 03:20:17.643500: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2022-05-04 03:20:17.643584: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-05-04 03:20:17.644084: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-05-04 03:20:17.645222: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2022-05-04 03:20:17.645275: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2022-05-04 03:20:17.645291: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2022-05-04 03:20:17.645305: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2022-05-04 03:20:17.645420: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-05-04 03:20:17.645863: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-05-04 03:20:17.646255: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14257 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-4675\n",
            "I0504 03:20:17.647334 140467053463424 saver.py:1284] Restoring parameters from training/model.ckpt-4675\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0504 03:20:18.582401 140467053463424 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0504 03:20:18.707544 140467053463424 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 253 images.\n",
            "I0504 03:20:42.637633 140464533837568 coco_evaluation.py:293] Performing evaluation on 253 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I0504 03:20:42.643369 140464533837568 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.06s)\n",
            "I0504 03:20:42.702882 140464533837568 coco_tools.py:138] DONE (t=0.06s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=17.33s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.56s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.001\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.011\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.018\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.005\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
            "INFO:tensorflow:Finished evaluation at 2022-05-04-03:21:00\n",
            "I0504 03:21:00.771588 140467053463424 evaluation.py:275] Finished evaluation at 2022-05-04-03:21:00\n",
            "INFO:tensorflow:Saving dict for global step 4675: DetectionBoxes_Precision/mAP = 3.7338115e-05, DetectionBoxes_Precision/mAP (large) = 0.0, DetectionBoxes_Precision/mAP (medium) = 0.00022474104, DetectionBoxes_Precision/mAP (small) = 4.4885295e-05, DetectionBoxes_Precision/mAP@.50IOU = 0.00015786936, DetectionBoxes_Precision/mAP@.75IOU = 7.284419e-06, DetectionBoxes_Recall/AR@1 = 5.574136e-05, DetectionBoxes_Recall/AR@10 = 0.0007949168, DetectionBoxes_Recall/AR@100 = 0.010610524, DetectionBoxes_Recall/AR@100 (large) = 0.0, DetectionBoxes_Recall/AR@100 (medium) = 0.0053702584, DetectionBoxes_Recall/AR@100 (small) = 0.018418254, Loss/BoxClassifierLoss/classification_loss = 0.20296168, Loss/BoxClassifierLoss/localization_loss = 0.06504157, Loss/RPNLoss/localization_loss = 0.52850163, Loss/RPNLoss/objectness_loss = 0.39747927, Loss/total_loss = 1.1939844, global_step = 4675, learning_rate = 0.0002, loss = 1.1939844\n",
            "I0504 03:21:00.771894 140467053463424 estimator.py:2049] Saving dict for global step 4675: DetectionBoxes_Precision/mAP = 3.7338115e-05, DetectionBoxes_Precision/mAP (large) = 0.0, DetectionBoxes_Precision/mAP (medium) = 0.00022474104, DetectionBoxes_Precision/mAP (small) = 4.4885295e-05, DetectionBoxes_Precision/mAP@.50IOU = 0.00015786936, DetectionBoxes_Precision/mAP@.75IOU = 7.284419e-06, DetectionBoxes_Recall/AR@1 = 5.574136e-05, DetectionBoxes_Recall/AR@10 = 0.0007949168, DetectionBoxes_Recall/AR@100 = 0.010610524, DetectionBoxes_Recall/AR@100 (large) = 0.0, DetectionBoxes_Recall/AR@100 (medium) = 0.0053702584, DetectionBoxes_Recall/AR@100 (small) = 0.018418254, Loss/BoxClassifierLoss/classification_loss = 0.20296168, Loss/BoxClassifierLoss/localization_loss = 0.06504157, Loss/RPNLoss/localization_loss = 0.52850163, Loss/RPNLoss/objectness_loss = 0.39747927, Loss/total_loss = 1.1939844, global_step = 4675, learning_rate = 0.0002, loss = 1.1939844\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 4675: training/model.ckpt-4675\n",
            "I0504 03:21:01.550220 140467053463424 estimator.py:2109] Saving 'checkpoint_path' summary for global step 4675: training/model.ckpt-4675\n",
            "INFO:tensorflow:global_step/sec: 1.65977\n",
            "I0504 03:21:04.217452 140467053463424 basic_session_run_hooks.py:692] global_step/sec: 1.65977\n",
            "INFO:tensorflow:loss = 3.4332817, step = 4700 (60.249 sec)\n",
            "I0504 03:21:04.218386 140467053463424 basic_session_run_hooks.py:260] loss = 3.4332817, step = 4700 (60.249 sec)\n",
            "INFO:tensorflow:global_step/sec: 10.3031\n",
            "I0504 03:21:13.923298 140467053463424 basic_session_run_hooks.py:692] global_step/sec: 10.3031\n",
            "INFO:tensorflow:loss = 0.94987094, step = 4800 (9.706 sec)\n",
            "I0504 03:21:13.924388 140467053463424 basic_session_run_hooks.py:260] loss = 0.94987094, step = 4800 (9.706 sec)\n",
            "INFO:tensorflow:global_step/sec: 10.1301\n",
            "I0504 03:21:23.794894 140467053463424 basic_session_run_hooks.py:692] global_step/sec: 10.1301\n",
            "INFO:tensorflow:loss = 1.8260175, step = 4900 (9.872 sec)\n",
            "I0504 03:21:23.795955 140467053463424 basic_session_run_hooks.py:260] loss = 1.8260175, step = 4900 (9.872 sec)\n",
            "INFO:tensorflow:global_step/sec: 10.1529\n",
            "I0504 03:21:33.644268 140467053463424 basic_session_run_hooks.py:692] global_step/sec: 10.1529\n",
            "INFO:tensorflow:loss = 3.2670276, step = 5000 (9.849 sec)\n",
            "I0504 03:21:33.645230 140467053463424 basic_session_run_hooks.py:260] loss = 3.2670276, step = 5000 (9.849 sec)\n",
            "INFO:tensorflow:global_step/sec: 10.2138\n",
            "I0504 03:21:43.434974 140467053463424 basic_session_run_hooks.py:692] global_step/sec: 10.2138\n",
            "INFO:tensorflow:loss = 1.9327097, step = 5100 (9.791 sec)\n",
            "I0504 03:21:43.436067 140467053463424 basic_session_run_hooks.py:260] loss = 1.9327097, step = 5100 (9.791 sec)\n",
            "INFO:tensorflow:global_step/sec: 10.2535\n",
            "I0504 03:21:53.187768 140467053463424 basic_session_run_hooks.py:692] global_step/sec: 10.2535\n",
            "INFO:tensorflow:loss = 1.587128, step = 5200 (9.753 sec)\n",
            "I0504 03:21:53.188800 140467053463424 basic_session_run_hooks.py:260] loss = 1.587128, step = 5200 (9.753 sec)\n",
            "INFO:tensorflow:global_step/sec: 10.3629\n",
            "I0504 03:22:02.837571 140467053463424 basic_session_run_hooks.py:692] global_step/sec: 10.3629\n",
            "INFO:tensorflow:loss = 1.6206403, step = 5300 (9.650 sec)\n",
            "I0504 03:22:02.838491 140467053463424 basic_session_run_hooks.py:260] loss = 1.6206403, step = 5300 (9.650 sec)\n",
            "INFO:tensorflow:global_step/sec: 10.3362\n",
            "I0504 03:22:12.512336 140467053463424 basic_session_run_hooks.py:692] global_step/sec: 10.3362\n",
            "INFO:tensorflow:loss = 2.241274, step = 5400 (9.675 sec)\n",
            "I0504 03:22:12.513381 140467053463424 basic_session_run_hooks.py:260] loss = 2.241274, step = 5400 (9.675 sec)\n",
            "INFO:tensorflow:global_step/sec: 10.4197\n",
            "I0504 03:22:22.109501 140467053463424 basic_session_run_hooks.py:692] global_step/sec: 10.4197\n",
            "INFO:tensorflow:loss = 0.69526047, step = 5500 (9.597 sec)\n",
            "I0504 03:22:22.110538 140467053463424 basic_session_run_hooks.py:260] loss = 0.69526047, step = 5500 (9.597 sec)\n",
            "INFO:tensorflow:global_step/sec: 10.4055\n",
            "I0504 03:22:31.719828 140467053463424 basic_session_run_hooks.py:692] global_step/sec: 10.4055\n",
            "INFO:tensorflow:loss = 2.4446225, step = 5600 (9.610 sec)\n",
            "I0504 03:22:31.720918 140467053463424 basic_session_run_hooks.py:260] loss = 2.4446225, step = 5600 (9.610 sec)\n",
            "INFO:tensorflow:global_step/sec: 10.298\n",
            "I0504 03:22:41.430461 140467053463424 basic_session_run_hooks.py:692] global_step/sec: 10.298\n",
            "INFO:tensorflow:loss = 0.9637233, step = 5700 (9.710 sec)\n",
            "I0504 03:22:41.431384 140467053463424 basic_session_run_hooks.py:260] loss = 0.9637233, step = 5700 (9.710 sec)\n",
            "INFO:tensorflow:global_step/sec: 10.2113\n",
            "I0504 03:22:51.223499 140467053463424 basic_session_run_hooks.py:692] global_step/sec: 10.2113\n",
            "INFO:tensorflow:loss = 1.5898856, step = 5800 (9.793 sec)\n",
            "I0504 03:22:51.224299 140467053463424 basic_session_run_hooks.py:260] loss = 1.5898856, step = 5800 (9.793 sec)\n",
            "INFO:tensorflow:global_step/sec: 10.1803\n",
            "I0504 03:23:01.046412 140467053463424 basic_session_run_hooks.py:692] global_step/sec: 10.1803\n",
            "INFO:tensorflow:loss = 2.0929766, step = 5900 (9.823 sec)\n",
            "I0504 03:23:01.047279 140467053463424 basic_session_run_hooks.py:260] loss = 2.0929766, step = 5900 (9.823 sec)\n",
            "INFO:tensorflow:global_step/sec: 10.2868\n",
            "I0504 03:23:10.767639 140467053463424 basic_session_run_hooks.py:692] global_step/sec: 10.2868\n",
            "INFO:tensorflow:loss = 2.0434744, step = 6000 (9.722 sec)\n",
            "I0504 03:23:10.768829 140467053463424 basic_session_run_hooks.py:260] loss = 2.0434744, step = 6000 (9.722 sec)\n",
            "INFO:tensorflow:global_step/sec: 10.2633\n",
            "I0504 03:23:20.511115 140467053463424 basic_session_run_hooks.py:692] global_step/sec: 10.2633\n",
            "INFO:tensorflow:loss = 1.2047591, step = 6100 (9.743 sec)\n",
            "I0504 03:23:20.512193 140467053463424 basic_session_run_hooks.py:260] loss = 1.2047591, step = 6100 (9.743 sec)\n",
            "INFO:tensorflow:global_step/sec: 10.3315\n",
            "I0504 03:23:30.190237 140467053463424 basic_session_run_hooks.py:692] global_step/sec: 10.3315\n",
            "INFO:tensorflow:loss = 1.2650973, step = 6200 (9.679 sec)\n",
            "I0504 03:23:30.191225 140467053463424 basic_session_run_hooks.py:260] loss = 1.2650973, step = 6200 (9.679 sec)\n",
            "INFO:tensorflow:global_step/sec: 10.3963\n",
            "I0504 03:23:39.809037 140467053463424 basic_session_run_hooks.py:692] global_step/sec: 10.3963\n",
            "INFO:tensorflow:loss = 0.72722185, step = 6300 (9.619 sec)\n",
            "I0504 03:23:39.809999 140467053463424 basic_session_run_hooks.py:260] loss = 0.72722185, step = 6300 (9.619 sec)\n",
            "INFO:tensorflow:global_step/sec: 10.3778\n",
            "I0504 03:23:49.444947 140467053463424 basic_session_run_hooks.py:692] global_step/sec: 10.3778\n",
            "INFO:tensorflow:loss = 1.4908723, step = 6400 (9.636 sec)\n",
            "I0504 03:23:49.445838 140467053463424 basic_session_run_hooks.py:260] loss = 1.4908723, step = 6400 (9.636 sec)\n",
            "INFO:tensorflow:global_step/sec: 10.4101\n",
            "I0504 03:23:59.050987 140467053463424 basic_session_run_hooks.py:692] global_step/sec: 10.4101\n",
            "INFO:tensorflow:loss = 1.7518532, step = 6500 (9.606 sec)\n",
            "I0504 03:23:59.051987 140467053463424 basic_session_run_hooks.py:260] loss = 1.7518532, step = 6500 (9.606 sec)\n",
            "INFO:tensorflow:global_step/sec: 10.2491\n",
            "I0504 03:24:08.807976 140467053463424 basic_session_run_hooks.py:692] global_step/sec: 10.2491\n",
            "INFO:tensorflow:loss = 1.6297358, step = 6600 (9.757 sec)\n",
            "I0504 03:24:08.809106 140467053463424 basic_session_run_hooks.py:260] loss = 1.6297358, step = 6600 (9.757 sec)\n",
            "INFO:tensorflow:global_step/sec: 10.327\n",
            "I0504 03:24:18.491326 140467053463424 basic_session_run_hooks.py:692] global_step/sec: 10.327\n",
            "INFO:tensorflow:loss = 2.5513353, step = 6700 (9.683 sec)\n",
            "I0504 03:24:18.492251 140467053463424 basic_session_run_hooks.py:260] loss = 2.5513353, step = 6700 (9.683 sec)\n",
            "INFO:tensorflow:global_step/sec: 10.3285\n",
            "I0504 03:24:28.173255 140467053463424 basic_session_run_hooks.py:692] global_step/sec: 10.3285\n",
            "INFO:tensorflow:loss = 1.642739, step = 6800 (9.682 sec)\n",
            "I0504 03:24:28.174400 140467053463424 basic_session_run_hooks.py:260] loss = 1.642739, step = 6800 (9.682 sec)\n",
            "INFO:tensorflow:global_step/sec: 10.3657\n",
            "I0504 03:24:37.820509 140467053463424 basic_session_run_hooks.py:692] global_step/sec: 10.3657\n",
            "INFO:tensorflow:loss = 1.4393426, step = 6900 (9.647 sec)\n",
            "I0504 03:24:37.821550 140467053463424 basic_session_run_hooks.py:260] loss = 1.4393426, step = 6900 (9.647 sec)\n",
            "INFO:tensorflow:global_step/sec: 10.3407\n",
            "I0504 03:24:47.491009 140467053463424 basic_session_run_hooks.py:692] global_step/sec: 10.3407\n",
            "INFO:tensorflow:loss = 2.6273665, step = 7000 (9.671 sec)\n",
            "I0504 03:24:47.492085 140467053463424 basic_session_run_hooks.py:260] loss = 2.6273665, step = 7000 (9.671 sec)\n",
            "INFO:tensorflow:global_step/sec: 10.3091\n",
            "I0504 03:24:57.191121 140467053463424 basic_session_run_hooks.py:692] global_step/sec: 10.3091\n",
            "INFO:tensorflow:loss = 0.855739, step = 7100 (9.700 sec)\n",
            "I0504 03:24:57.192066 140467053463424 basic_session_run_hooks.py:260] loss = 0.855739, step = 7100 (9.700 sec)\n",
            "INFO:tensorflow:global_step/sec: 10.3008\n",
            "I0504 03:25:06.899086 140467053463424 basic_session_run_hooks.py:692] global_step/sec: 10.3008\n",
            "INFO:tensorflow:loss = 3.8498542, step = 7200 (9.708 sec)\n",
            "I0504 03:25:06.900047 140467053463424 basic_session_run_hooks.py:260] loss = 3.8498542, step = 7200 (9.708 sec)\n",
            "INFO:tensorflow:global_step/sec: 10.2922\n",
            "I0504 03:25:16.615207 140467053463424 basic_session_run_hooks.py:692] global_step/sec: 10.2922\n",
            "INFO:tensorflow:loss = 2.9078445, step = 7300 (9.716 sec)\n",
            "I0504 03:25:16.616395 140467053463424 basic_session_run_hooks.py:260] loss = 2.9078445, step = 7300 (9.716 sec)\n",
            "INFO:tensorflow:global_step/sec: 10.3568\n",
            "I0504 03:25:26.270677 140467053463424 basic_session_run_hooks.py:692] global_step/sec: 10.3568\n",
            "INFO:tensorflow:loss = 2.6807537, step = 7400 (9.655 sec)\n",
            "I0504 03:25:26.271492 140467053463424 basic_session_run_hooks.py:260] loss = 2.6807537, step = 7400 (9.655 sec)\n",
            "INFO:tensorflow:global_step/sec: 10.3241\n",
            "I0504 03:25:35.956715 140467053463424 basic_session_run_hooks.py:692] global_step/sec: 10.3241\n",
            "INFO:tensorflow:loss = 2.6619995, step = 7500 (9.686 sec)\n",
            "I0504 03:25:35.957571 140467053463424 basic_session_run_hooks.py:260] loss = 2.6619995, step = 7500 (9.686 sec)\n",
            "INFO:tensorflow:global_step/sec: 10.3073\n",
            "I0504 03:25:45.658601 140467053463424 basic_session_run_hooks.py:692] global_step/sec: 10.3073\n",
            "INFO:tensorflow:loss = 1.580826, step = 7600 (9.702 sec)\n",
            "I0504 03:25:45.659821 140467053463424 basic_session_run_hooks.py:260] loss = 1.580826, step = 7600 (9.702 sec)\n",
            "INFO:tensorflow:global_step/sec: 10.3261\n",
            "I0504 03:25:55.342768 140467053463424 basic_session_run_hooks.py:692] global_step/sec: 10.3261\n",
            "INFO:tensorflow:loss = 1.763913, step = 7700 (9.684 sec)\n",
            "I0504 03:25:55.343795 140467053463424 basic_session_run_hooks.py:260] loss = 1.763913, step = 7700 (9.684 sec)\n",
            "INFO:tensorflow:global_step/sec: 10.2092\n",
            "I0504 03:26:05.137813 140467053463424 basic_session_run_hooks.py:692] global_step/sec: 10.2092\n",
            "INFO:tensorflow:loss = 2.7762678, step = 7800 (9.795 sec)\n",
            "I0504 03:26:05.138650 140467053463424 basic_session_run_hooks.py:260] loss = 2.7762678, step = 7800 (9.795 sec)\n",
            "INFO:tensorflow:global_step/sec: 10.3073\n",
            "I0504 03:26:14.839771 140467053463424 basic_session_run_hooks.py:692] global_step/sec: 10.3073\n",
            "INFO:tensorflow:loss = 3.4392505, step = 7900 (9.702 sec)\n",
            "I0504 03:26:14.840732 140467053463424 basic_session_run_hooks.py:260] loss = 3.4392505, step = 7900 (9.702 sec)\n",
            "INFO:tensorflow:global_step/sec: 10.2097\n",
            "I0504 03:26:24.634384 140467053463424 basic_session_run_hooks.py:692] global_step/sec: 10.2097\n",
            "INFO:tensorflow:loss = 2.4471917, step = 8000 (9.795 sec)\n",
            "I0504 03:26:24.635405 140467053463424 basic_session_run_hooks.py:260] loss = 2.4471917, step = 8000 (9.795 sec)\n",
            "INFO:tensorflow:global_step/sec: 10.3756\n",
            "I0504 03:26:34.272406 140467053463424 basic_session_run_hooks.py:692] global_step/sec: 10.3756\n",
            "INFO:tensorflow:loss = 1.0696381, step = 8100 (9.638 sec)\n",
            "I0504 03:26:34.273506 140467053463424 basic_session_run_hooks.py:260] loss = 1.0696381, step = 8100 (9.638 sec)\n",
            "INFO:tensorflow:global_step/sec: 10.2908\n",
            "I0504 03:26:43.989838 140467053463424 basic_session_run_hooks.py:692] global_step/sec: 10.2908\n",
            "INFO:tensorflow:loss = 1.6102489, step = 8200 (9.717 sec)\n",
            "I0504 03:26:43.990951 140467053463424 basic_session_run_hooks.py:260] loss = 1.6102489, step = 8200 (9.717 sec)\n",
            "INFO:tensorflow:global_step/sec: 10.3446\n",
            "I0504 03:26:53.656756 140467053463424 basic_session_run_hooks.py:692] global_step/sec: 10.3446\n",
            "INFO:tensorflow:loss = 1.53796, step = 8300 (9.667 sec)\n",
            "I0504 03:26:53.657959 140467053463424 basic_session_run_hooks.py:260] loss = 1.53796, step = 8300 (9.667 sec)\n",
            "INFO:tensorflow:global_step/sec: 10.2319\n",
            "I0504 03:27:03.430075 140467053463424 basic_session_run_hooks.py:692] global_step/sec: 10.2319\n",
            "INFO:tensorflow:loss = 2.8225627, step = 8400 (9.773 sec)\n",
            "I0504 03:27:03.431140 140467053463424 basic_session_run_hooks.py:260] loss = 2.8225627, step = 8400 (9.773 sec)\n",
            "INFO:tensorflow:global_step/sec: 10.3184\n",
            "I0504 03:27:13.121495 140467053463424 basic_session_run_hooks.py:692] global_step/sec: 10.3184\n",
            "INFO:tensorflow:loss = 2.534142, step = 8500 (9.691 sec)\n",
            "I0504 03:27:13.122561 140467053463424 basic_session_run_hooks.py:260] loss = 2.534142, step = 8500 (9.691 sec)\n",
            "INFO:tensorflow:global_step/sec: 10.2399\n",
            "I0504 03:27:22.887259 140467053463424 basic_session_run_hooks.py:692] global_step/sec: 10.2399\n",
            "INFO:tensorflow:loss = 0.43955088, step = 8600 (9.766 sec)\n",
            "I0504 03:27:22.888334 140467053463424 basic_session_run_hooks.py:260] loss = 0.43955088, step = 8600 (9.766 sec)\n",
            "INFO:tensorflow:global_step/sec: 10.316\n",
            "I0504 03:27:32.580891 140467053463424 basic_session_run_hooks.py:692] global_step/sec: 10.316\n",
            "INFO:tensorflow:loss = 4.1174545, step = 8700 (9.694 sec)\n",
            "I0504 03:27:32.582426 140467053463424 basic_session_run_hooks.py:260] loss = 4.1174545, step = 8700 (9.694 sec)\n",
            "INFO:tensorflow:global_step/sec: 10.2866\n",
            "I0504 03:27:42.302295 140467053463424 basic_session_run_hooks.py:692] global_step/sec: 10.2866\n",
            "INFO:tensorflow:loss = 2.3114288, step = 8800 (9.721 sec)\n",
            "I0504 03:27:42.303249 140467053463424 basic_session_run_hooks.py:260] loss = 2.3114288, step = 8800 (9.721 sec)\n",
            "INFO:tensorflow:global_step/sec: 10.2618\n",
            "I0504 03:27:52.047218 140467053463424 basic_session_run_hooks.py:692] global_step/sec: 10.2618\n",
            "INFO:tensorflow:loss = 1.30684, step = 8900 (9.745 sec)\n",
            "I0504 03:27:52.048225 140467053463424 basic_session_run_hooks.py:260] loss = 1.30684, step = 8900 (9.745 sec)\n",
            "INFO:tensorflow:global_step/sec: 10.2794\n",
            "I0504 03:28:01.775405 140467053463424 basic_session_run_hooks.py:692] global_step/sec: 10.2794\n",
            "INFO:tensorflow:loss = 1.5103698, step = 9000 (9.728 sec)\n",
            "I0504 03:28:01.776445 140467053463424 basic_session_run_hooks.py:260] loss = 1.5103698, step = 9000 (9.728 sec)\n",
            "INFO:tensorflow:global_step/sec: 10.3073\n",
            "I0504 03:28:11.477324 140467053463424 basic_session_run_hooks.py:692] global_step/sec: 10.3073\n",
            "INFO:tensorflow:loss = 2.0329523, step = 9100 (9.702 sec)\n",
            "I0504 03:28:11.478451 140467053463424 basic_session_run_hooks.py:260] loss = 2.0329523, step = 9100 (9.702 sec)\n",
            "INFO:tensorflow:global_step/sec: 10.2975\n",
            "I0504 03:28:21.188413 140467053463424 basic_session_run_hooks.py:692] global_step/sec: 10.2975\n",
            "INFO:tensorflow:loss = 3.4089024, step = 9200 (9.711 sec)\n",
            "I0504 03:28:21.189593 140467053463424 basic_session_run_hooks.py:260] loss = 3.4089024, step = 9200 (9.711 sec)\n",
            "INFO:tensorflow:global_step/sec: 10.2669\n",
            "I0504 03:28:30.928511 140467053463424 basic_session_run_hooks.py:692] global_step/sec: 10.2669\n",
            "INFO:tensorflow:loss = 0.5359163, step = 9300 (9.740 sec)\n",
            "I0504 03:28:30.929648 140467053463424 basic_session_run_hooks.py:260] loss = 0.5359163, step = 9300 (9.740 sec)\n",
            "INFO:tensorflow:global_step/sec: 10.3074\n",
            "I0504 03:28:40.630253 140467053463424 basic_session_run_hooks.py:692] global_step/sec: 10.3074\n",
            "INFO:tensorflow:loss = 2.6017914, step = 9400 (9.702 sec)\n",
            "I0504 03:28:40.631316 140467053463424 basic_session_run_hooks.py:260] loss = 2.6017914, step = 9400 (9.702 sec)\n",
            "INFO:tensorflow:global_step/sec: 10.2819\n",
            "I0504 03:28:50.356114 140467053463424 basic_session_run_hooks.py:692] global_step/sec: 10.2819\n",
            "INFO:tensorflow:loss = 1.1647203, step = 9500 (9.726 sec)\n",
            "I0504 03:28:50.357117 140467053463424 basic_session_run_hooks.py:260] loss = 1.1647203, step = 9500 (9.726 sec)\n",
            "INFO:tensorflow:global_step/sec: 10.2726\n",
            "I0504 03:29:00.090780 140467053463424 basic_session_run_hooks.py:692] global_step/sec: 10.2726\n",
            "INFO:tensorflow:loss = 1.4642645, step = 9600 (9.735 sec)\n",
            "I0504 03:29:00.091861 140467053463424 basic_session_run_hooks.py:260] loss = 1.4642645, step = 9600 (9.735 sec)\n",
            "INFO:tensorflow:global_step/sec: 10.1751\n",
            "I0504 03:29:09.918612 140467053463424 basic_session_run_hooks.py:692] global_step/sec: 10.1751\n",
            "INFO:tensorflow:loss = 1.0811844, step = 9700 (9.828 sec)\n",
            "I0504 03:29:09.919425 140467053463424 basic_session_run_hooks.py:260] loss = 1.0811844, step = 9700 (9.828 sec)\n",
            "INFO:tensorflow:global_step/sec: 10.3022\n",
            "I0504 03:29:19.625326 140467053463424 basic_session_run_hooks.py:692] global_step/sec: 10.3022\n",
            "INFO:tensorflow:loss = 2.4089096, step = 9800 (9.707 sec)\n",
            "I0504 03:29:19.626420 140467053463424 basic_session_run_hooks.py:260] loss = 2.4089096, step = 9800 (9.707 sec)\n",
            "INFO:tensorflow:global_step/sec: 10.3492\n",
            "I0504 03:29:29.287851 140467053463424 basic_session_run_hooks.py:692] global_step/sec: 10.3492\n",
            "INFO:tensorflow:loss = 1.2389417, step = 9900 (9.663 sec)\n",
            "I0504 03:29:29.288973 140467053463424 basic_session_run_hooks.py:260] loss = 1.2389417, step = 9900 (9.663 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 10000 into training/model.ckpt.\n",
            "I0504 03:29:38.886547 140467053463424 basic_session_run_hooks.py:606] Saving checkpoints for 10000 into training/model.ckpt.\n",
            "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
            "I0504 03:29:39.694334 140467053463424 training.py:527] Skip the current checkpoint eval due to throttle secs (600 secs).\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/tensorflow-object-detection-faster-rcnn/data/valid/celll.tfrecord']\n",
            "I0504 03:29:39.717782 140467053463424 dataset_builder.py:162] Reading unweighted datasets: ['/content/tensorflow-object-detection-faster-rcnn/data/valid/celll.tfrecord']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/tensorflow-object-detection-faster-rcnn/data/valid/celll.tfrecord']\n",
            "I0504 03:29:39.718516 140467053463424 dataset_builder.py:79] Reading record datasets for input file: ['/content/tensorflow-object-detection-faster-rcnn/data/valid/celll.tfrecord']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I0504 03:29:39.718670 140467053463424 dataset_builder.py:80] Number of filenames to read: 1\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0504 03:29:40.479556 140467053463424 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0504 03:29:41.696802 140467053463424 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0504 03:29:41.820863 140467053463424 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0504 03:29:41.821228 140467053463424 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0504 03:29:42.728586 140467053463424 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0504 03:29:42.743425 140467053463424 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0504 03:29:44.646895 140467053463424 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2022-05-04T03:29:44Z\n",
            "I0504 03:29:44.662366 140467053463424 evaluation.py:255] Starting evaluation at 2022-05-04T03:29:44Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0504 03:29:45.080864 140467053463424 monitored_session.py:240] Graph was finalized.\n",
            "2022-05-04 03:29:45.081559: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-05-04 03:29:45.081999: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2022-05-04 03:29:45.082133: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2022-05-04 03:29:45.082185: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2022-05-04 03:29:45.082217: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2022-05-04 03:29:45.082245: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2022-05-04 03:29:45.082269: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2022-05-04 03:29:45.082294: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2022-05-04 03:29:45.082321: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2022-05-04 03:29:45.082417: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-05-04 03:29:45.082808: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-05-04 03:29:45.083113: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2022-05-04 03:29:45.083164: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2022-05-04 03:29:45.083178: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2022-05-04 03:29:45.083188: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2022-05-04 03:29:45.083299: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-05-04 03:29:45.083668: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-05-04 03:29:45.083989: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14257 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-10000\n",
            "I0504 03:29:45.085050 140467053463424 saver.py:1284] Restoring parameters from training/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0504 03:29:46.041585 140467053463424 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0504 03:29:46.186808 140467053463424 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 253 images.\n",
            "I0504 03:30:07.045989 140464533837568 coco_evaluation.py:293] Performing evaluation on 253 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I0504 03:30:07.049703 140464533837568 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.06s)\n",
            "I0504 03:30:07.112450 140464533837568 coco_tools.py:138] DONE (t=0.06s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=17.39s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.55s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.001\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.002\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.001\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.011\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.018\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.006\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
            "INFO:tensorflow:Finished evaluation at 2022-05-04-03:30:25\n",
            "I0504 03:30:25.227049 140467053463424 evaluation.py:275] Finished evaluation at 2022-05-04-03:30:25\n",
            "INFO:tensorflow:Saving dict for global step 10000: DetectionBoxes_Precision/mAP = 0.00015198869, DetectionBoxes_Precision/mAP (large) = 0.0, DetectionBoxes_Precision/mAP (medium) = 0.002227971, DetectionBoxes_Precision/mAP (small) = 0.00038374244, DetectionBoxes_Precision/mAP@.50IOU = 0.0012448281, DetectionBoxes_Precision/mAP@.75IOU = 1.4612762e-05, DetectionBoxes_Recall/AR@1 = 1.1148272e-05, DetectionBoxes_Recall/AR@10 = 0.00077699637, DetectionBoxes_Recall/AR@100 = 0.010577076, DetectionBoxes_Recall/AR@100 (large) = 0.0, DetectionBoxes_Recall/AR@100 (medium) = 0.0060480214, DetectionBoxes_Recall/AR@100 (small) = 0.017939916, Loss/BoxClassifierLoss/classification_loss = 0.18933839, Loss/BoxClassifierLoss/localization_loss = 0.06603542, Loss/RPNLoss/localization_loss = 0.53061485, Loss/RPNLoss/objectness_loss = 0.38962117, Loss/total_loss = 1.1756101, global_step = 10000, learning_rate = 0.0002, loss = 1.1756101\n",
            "I0504 03:30:25.227347 140467053463424 estimator.py:2049] Saving dict for global step 10000: DetectionBoxes_Precision/mAP = 0.00015198869, DetectionBoxes_Precision/mAP (large) = 0.0, DetectionBoxes_Precision/mAP (medium) = 0.002227971, DetectionBoxes_Precision/mAP (small) = 0.00038374244, DetectionBoxes_Precision/mAP@.50IOU = 0.0012448281, DetectionBoxes_Precision/mAP@.75IOU = 1.4612762e-05, DetectionBoxes_Recall/AR@1 = 1.1148272e-05, DetectionBoxes_Recall/AR@10 = 0.00077699637, DetectionBoxes_Recall/AR@100 = 0.010577076, DetectionBoxes_Recall/AR@100 (large) = 0.0, DetectionBoxes_Recall/AR@100 (medium) = 0.0060480214, DetectionBoxes_Recall/AR@100 (small) = 0.017939916, Loss/BoxClassifierLoss/classification_loss = 0.18933839, Loss/BoxClassifierLoss/localization_loss = 0.06603542, Loss/RPNLoss/localization_loss = 0.53061485, Loss/RPNLoss/objectness_loss = 0.38962117, Loss/total_loss = 1.1756101, global_step = 10000, learning_rate = 0.0002, loss = 1.1756101\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 10000: training/model.ckpt-10000\n",
            "I0504 03:30:25.230547 140467053463424 estimator.py:2109] Saving 'checkpoint_path' summary for global step 10000: training/model.ckpt-10000\n",
            "INFO:tensorflow:Performing the final export in the end of training.\n",
            "I0504 03:30:25.231239 140467053463424 exporter.py:410] Performing the final export in the end of training.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0504 03:30:25.508779 140467053463424 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0504 03:30:26.743725 140467053463424 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0504 03:30:26.864705 140467053463424 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0504 03:30:26.865086 140467053463424 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0504 03:30:27.780453 140467053463424 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0504 03:30:27.795413 140467053463424 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0504 03:30:28.548861 140467053463424 estimator.py:1150] Done calling model_fn.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
            "W0504 03:30:28.549128 140467053463424 deprecation.py:323] From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
            "I0504 03:30:28.549681 140467053463424 export_utils.py:170] Signatures INCLUDED in export for Classify: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
            "I0504 03:30:28.549804 140467053463424 export_utils.py:170] Signatures INCLUDED in export for Regress: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['tensorflow/serving/predict', 'serving_default']\n",
            "I0504 03:30:28.549879 140467053463424 export_utils.py:170] Signatures INCLUDED in export for Predict: ['tensorflow/serving/predict', 'serving_default']\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
            "I0504 03:30:28.549944 140467053463424 export_utils.py:170] Signatures INCLUDED in export for Train: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
            "I0504 03:30:28.550004 140467053463424 export_utils.py:170] Signatures INCLUDED in export for Eval: None\n",
            "2022-05-04 03:30:28.550533: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-05-04 03:30:28.550926: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2022-05-04 03:30:28.551029: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2022-05-04 03:30:28.551057: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2022-05-04 03:30:28.551080: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2022-05-04 03:30:28.551104: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2022-05-04 03:30:28.551132: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2022-05-04 03:30:28.551166: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2022-05-04 03:30:28.551189: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2022-05-04 03:30:28.551280: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-05-04 03:30:28.551653: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-05-04 03:30:28.551968: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2022-05-04 03:30:28.552008: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2022-05-04 03:30:28.552021: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2022-05-04 03:30:28.552032: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2022-05-04 03:30:28.552140: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-05-04 03:30:28.552521: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-05-04 03:30:28.552866: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14257 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-10000\n",
            "I0504 03:30:28.555117 140467053463424 saver.py:1284] Restoring parameters from training/model.ckpt-10000\n",
            "INFO:tensorflow:Assets added to graph.\n",
            "I0504 03:30:29.051478 140467053463424 builder_impl.py:665] Assets added to graph.\n",
            "INFO:tensorflow:No assets to write.\n",
            "I0504 03:30:29.051686 140467053463424 builder_impl.py:460] No assets to write.\n",
            "INFO:tensorflow:SavedModel written to: training/export/Servo/temp-b'1651635025'/saved_model.pb\n",
            "I0504 03:30:29.832091 140467053463424 builder_impl.py:425] SavedModel written to: training/export/Servo/temp-b'1651635025'/saved_model.pb\n",
            "INFO:tensorflow:Loss for final step: 0.89485645.\n",
            "I0504 03:30:30.012405 140467053463424 estimator.py:371] Loss for final step: 0.89485645.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KP-tUdtnRybs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "fe0eb8dd-2292-422f-b7a1-12b34d3322bf"
      },
      "source": [
        "!ls {model_dir}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "checkpoint\t\t\t\t     model.ckpt-0.meta\n",
            "events.out.tfevents.1586733241.ae5063114bb0  model.ckpt-627.data-00000-of-00001\n",
            "graph.pbtxt\t\t\t\t     model.ckpt-627.index\n",
            "model.ckpt-0.data-00000-of-00001\t     model.ckpt-627.meta\n",
            "model.ckpt-0.index\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OmSESMetj1sa"
      },
      "source": [
        "## Exporting a Trained Inference Graph\n",
        "Once your training job is complete, you need to extract the newly trained inference graph, which will be later used to perform the object detection. This can be done as follows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHoP90pUyKSq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9cf13378-9525-4bf4-85aa-9c1cedc052ed"
      },
      "source": [
        "import re\n",
        "import numpy as np\n",
        "\n",
        "output_directory = './fine_tuned_model'\n",
        "\n",
        "lst = os.listdir(model_dir)\n",
        "lst = [l for l in lst if 'model.ckpt-' in l and '.meta' in l]\n",
        "steps=np.array([int(re.findall('\\d+', l)[0]) for l in lst])\n",
        "last_model = lst[steps.argmax()].replace('.meta', '')\n",
        "\n",
        "last_model_path = os.path.join(model_dir, last_model)\n",
        "print(last_model_path)\n",
        "!python /content/models/research/object_detection/export_inference_graph.py \\\n",
        "    --input_type=image_tensor \\\n",
        "    --pipeline_config_path={pipeline_fname} \\\n",
        "    --output_directory={output_directory} \\\n",
        "    --trained_checkpoint_prefix={last_model_path}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training/model.ckpt-627\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/export_inference_graph.py:162: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/export_inference_graph.py:145: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "W0412 23:24:51.738487 140044693362560 module_wrapper.py:139] From /content/models/research/object_detection/export_inference_graph.py:145: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:402: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
            "\n",
            "W0412 23:24:51.745003 140044693362560 module_wrapper.py:139] From /content/models/research/object_detection/exporter.py:402: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:121: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0412 23:24:51.745381 140044693362560 module_wrapper.py:139] From /content/models/research/object_detection/exporter.py:121: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/core/preprocessor.py:2689: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n",
            "\n",
            "W0412 23:24:51.786707 140044693362560 module_wrapper.py:139] From /content/models/research/object_detection/core/preprocessor.py:2689: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:168: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "W0412 23:24:51.832412 140044693362560 module_wrapper.py:139] From /content/models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:168: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:2784: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "W0412 23:24:51.841381 140044693362560 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:2784: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/core/anchor_generator.py:171: The name tf.assert_equal is deprecated. Please use tf.compat.v1.assert_equal instead.\n",
            "\n",
            "W0412 23:24:53.185800 140044693362560 module_wrapper.py:139] From /content/models/research/object_detection/core/anchor_generator.py:171: The name tf.assert_equal is deprecated. Please use tf.compat.v1.assert_equal instead.\n",
            "\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0412 23:24:53.192146 140044693362560 regularizers.py:98] Scale of 0 disables regularizer.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:558: The name tf.get_variable_scope is deprecated. Please use tf.compat.v1.get_variable_scope instead.\n",
            "\n",
            "W0412 23:24:53.192522 140044693362560 module_wrapper.py:139] From /content/models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:558: The name tf.get_variable_scope is deprecated. Please use tf.compat.v1.get_variable_scope instead.\n",
            "\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0412 23:24:53.206499 140044693362560 regularizers.py:98] Scale of 0 disables regularizer.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/predictors/convolutional_box_predictor.py:150: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "W0412 23:24:53.206881 140044693362560 module_wrapper.py:139] From /content/models/research/object_detection/predictors/convolutional_box_predictor.py:150: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0412 23:24:53.207002 140044693362560 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/core/box_list_ops.py:141: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0412 23:24:53.256133 140044693362560 deprecation.py:323] From /content/models/research/object_detection/core/box_list_ops.py:141: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/utils/spatial_transform_ops.py:419: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "box_ind is deprecated, use box_indices instead\n",
            "W0412 23:24:53.779789 140044693362560 deprecation.py:506] From /content/models/research/object_detection/utils/spatial_transform_ops.py:419: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "box_ind is deprecated, use box_indices instead\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:191: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
            "\n",
            "W0412 23:24:53.796557 140044693362560 module_wrapper.py:139] From /content/models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:191: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1634: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.flatten instead.\n",
            "W0412 23:24:54.364322 140044693362560 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1634: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.flatten instead.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0412 23:24:54.369531 140044693362560 regularizers.py:98] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0412 23:24:54.391574 140044693362560 regularizers.py:98] Scale of 0 disables regularizer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/dispatch.py:180: batch_gather (from tensorflow.python.ops.array_ops) is deprecated and will be removed after 2017-10-25.\n",
            "Instructions for updating:\n",
            "`tf.batch_gather` is deprecated, please use `tf.gather` with `batch_dims=-1` instead.\n",
            "W0412 23:24:54.982898 140044693362560 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/dispatch.py:180: batch_gather (from tensorflow.python.ops.array_ops) is deprecated and will be removed after 2017-10-25.\n",
            "Instructions for updating:\n",
            "`tf.batch_gather` is deprecated, please use `tf.gather` with `batch_dims=-1` instead.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:278: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n",
            "\n",
            "W0412 23:24:55.283099 140044693362560 module_wrapper.py:139] From /content/models/research/object_detection/exporter.py:278: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:383: get_or_create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please switch to tf.train.get_or_create_global_step\n",
            "W0412 23:24:55.283362 140044693362560 deprecation.py:323] From /content/models/research/object_detection/exporter.py:383: get_or_create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please switch to tf.train.get_or_create_global_step\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:415: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0412 23:24:55.286391 140044693362560 module_wrapper.py:139] From /content/models/research/object_detection/exporter.py:415: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:539: print_model_analysis (from tensorflow.contrib.tfprof.model_analyzer) is deprecated and will be removed after 2018-01-01.\n",
            "Instructions for updating:\n",
            "Use `tf.profiler.profile(graph, run_meta, op_log, cmd, options)`. Build `options` with `tf.profiler.ProfileOptionBuilder`. See README.md for details\n",
            "W0412 23:24:55.286567 140044693362560 deprecation.py:323] From /content/models/research/object_detection/exporter.py:539: print_model_analysis (from tensorflow.contrib.tfprof.model_analyzer) is deprecated and will be removed after 2018-01-01.\n",
            "Instructions for updating:\n",
            "Use `tf.profiler.profile(graph, run_meta, op_log, cmd, options)`. Build `options` with `tf.profiler.ProfileOptionBuilder`. See README.md for details\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/profiler/internal/flops_registry.py:142: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
            "W0412 23:24:55.287579 140044693362560 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/profiler/internal/flops_registry.py:142: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
            "236 ops no flops stats due to incomplete shapes.\n",
            "Parsing Inputs...\n",
            "Incomplete shape.\n",
            "\n",
            "=========================Options=============================\n",
            "-max_depth                  10000\n",
            "-min_bytes                  0\n",
            "-min_peak_bytes             0\n",
            "-min_residual_bytes         0\n",
            "-min_output_bytes           0\n",
            "-min_micros                 0\n",
            "-min_accelerator_micros     0\n",
            "-min_cpu_micros             0\n",
            "-min_params                 0\n",
            "-min_float_ops              0\n",
            "-min_occurrence             0\n",
            "-step                       -1\n",
            "-order_by                   name\n",
            "-account_type_regexes       _trainable_variables\n",
            "-start_name_regexes         .*\n",
            "-trim_name_regexes          .*BatchNorm.*\n",
            "-show_name_regexes          .*\n",
            "-hide_name_regexes          \n",
            "-account_displayed_op_only  true\n",
            "-select                     params\n",
            "-output                     stdout:\n",
            "\n",
            "==================Model Analysis Report======================\n",
            "Incomplete shape.\n",
            "\n",
            "Doc:\n",
            "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
            "param: Number of parameters (in the Variable).\n",
            "\n",
            "Profile:\n",
            "node name | # parameters\n",
            "_TFProfRoot (--/12.85m params)\n",
            "  Conv (--/2.65m params)\n",
            "    Conv/biases (512, 512/512 params)\n",
            "    Conv/weights (3x3x576x512, 2.65m/2.65m params)\n",
            "  FirstStageBoxPredictor (--/36.94k params)\n",
            "    FirstStageBoxPredictor/BoxEncodingPredictor (--/24.62k params)\n",
            "      FirstStageBoxPredictor/BoxEncodingPredictor/biases (48, 48/48 params)\n",
            "      FirstStageBoxPredictor/BoxEncodingPredictor/weights (1x1x512x48, 24.58k/24.58k params)\n",
            "    FirstStageBoxPredictor/ClassPredictor (--/12.31k params)\n",
            "      FirstStageBoxPredictor/ClassPredictor/biases (24, 24/24 params)\n",
            "      FirstStageBoxPredictor/ClassPredictor/weights (1x1x512x24, 12.29k/12.29k params)\n",
            "  FirstStageFeatureExtractor (--/4.25m params)\n",
            "    FirstStageFeatureExtractor/InceptionV2 (--/4.25m params)\n",
            "      FirstStageFeatureExtractor/InceptionV2/Conv2d_1a_7x7 (--/2.71k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Conv2d_1a_7x7/BatchNorm (--/0 params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Conv2d_1a_7x7/depthwise_weights (7x7x3x8, 1.18k/1.18k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Conv2d_1a_7x7/pointwise_weights (1x1x24x64, 1.54k/1.54k params)\n",
            "      FirstStageFeatureExtractor/InceptionV2/Conv2d_2b_1x1 (--/4.10k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Conv2d_2b_1x1/BatchNorm (--/0 params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Conv2d_2b_1x1/weights (1x1x64x64, 4.10k/4.10k params)\n",
            "      FirstStageFeatureExtractor/InceptionV2/Conv2d_2c_3x3 (--/110.59k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Conv2d_2c_3x3/BatchNorm (--/0 params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Conv2d_2c_3x3/weights (3x3x64x192, 110.59k/110.59k params)\n",
            "      FirstStageFeatureExtractor/InceptionV2/Mixed_3b (--/218.11k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_0 (--/12.29k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_0/Conv2d_0a_1x1 (--/12.29k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_0/Conv2d_0a_1x1/weights (1x1x192x64, 12.29k/12.29k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_1 (--/49.15k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_1/Conv2d_0a_1x1 (--/12.29k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_1/Conv2d_0a_1x1/weights (1x1x192x64, 12.29k/12.29k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_1/Conv2d_0b_3x3 (--/36.86k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_1/Conv2d_0b_3x3/weights (3x3x64x64, 36.86k/36.86k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2 (--/150.53k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2/Conv2d_0a_1x1 (--/12.29k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2/Conv2d_0a_1x1/weights (1x1x192x64, 12.29k/12.29k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2/Conv2d_0b_3x3 (--/55.30k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2/Conv2d_0b_3x3/weights (3x3x64x96, 55.30k/55.30k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2/Conv2d_0c_3x3 (--/82.94k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2/Conv2d_0c_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2/Conv2d_0c_3x3/weights (3x3x96x96, 82.94k/82.94k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_3 (--/6.14k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_3/Conv2d_0b_1x1 (--/6.14k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_3/Conv2d_0b_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_3/Conv2d_0b_1x1/weights (1x1x192x32, 6.14k/6.14k params)\n",
            "      FirstStageFeatureExtractor/InceptionV2/Mixed_3c (--/259.07k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_0 (--/16.38k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_0/Conv2d_0a_1x1 (--/16.38k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_0/Conv2d_0a_1x1/weights (1x1x256x64, 16.38k/16.38k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_1 (--/71.68k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_1/Conv2d_0a_1x1 (--/16.38k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_1/Conv2d_0a_1x1/weights (1x1x256x64, 16.38k/16.38k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_1/Conv2d_0b_3x3 (--/55.30k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_1/Conv2d_0b_3x3/weights (3x3x64x96, 55.30k/55.30k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2 (--/154.62k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2/Conv2d_0a_1x1 (--/16.38k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2/Conv2d_0a_1x1/weights (1x1x256x64, 16.38k/16.38k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2/Conv2d_0b_3x3 (--/55.30k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2/Conv2d_0b_3x3/weights (3x3x64x96, 55.30k/55.30k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2/Conv2d_0c_3x3 (--/82.94k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2/Conv2d_0c_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2/Conv2d_0c_3x3/weights (3x3x96x96, 82.94k/82.94k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_3 (--/16.38k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_3/Conv2d_0b_1x1 (--/16.38k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_3/Conv2d_0b_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_3/Conv2d_0b_1x1/weights (1x1x256x64, 16.38k/16.38k params)\n",
            "      FirstStageFeatureExtractor/InceptionV2/Mixed_4a (--/384.00k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_0 (--/225.28k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_0/Conv2d_0a_1x1 (--/40.96k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_0/Conv2d_0a_1x1/weights (1x1x320x128, 40.96k/40.96k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_0/Conv2d_1a_3x3 (--/184.32k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_0/Conv2d_1a_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_0/Conv2d_1a_3x3/weights (3x3x128x160, 184.32k/184.32k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1 (--/158.72k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1/Conv2d_0a_1x1 (--/20.48k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1/Conv2d_0a_1x1/weights (1x1x320x64, 20.48k/20.48k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1/Conv2d_0b_3x3 (--/55.30k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1/Conv2d_0b_3x3/weights (3x3x64x96, 55.30k/55.30k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1/Conv2d_1a_3x3 (--/82.94k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1/Conv2d_1a_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1/Conv2d_1a_3x3/weights (3x3x96x96, 82.94k/82.94k params)\n",
            "      FirstStageFeatureExtractor/InceptionV2/Mixed_4b (--/608.26k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_0 (--/129.02k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_0/Conv2d_0a_1x1 (--/129.02k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_0/Conv2d_0a_1x1/weights (1x1x576x224, 129.02k/129.02k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_1 (--/92.16k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_1/Conv2d_0a_1x1 (--/36.86k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_1/Conv2d_0a_1x1/weights (1x1x576x64, 36.86k/36.86k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_1/Conv2d_0b_3x3 (--/55.30k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_1/Conv2d_0b_3x3/weights (3x3x64x96, 55.30k/55.30k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2 (--/313.34k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2/Conv2d_0a_1x1 (--/55.30k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2/Conv2d_0a_1x1/weights (1x1x576x96, 55.30k/55.30k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2/Conv2d_0b_3x3 (--/110.59k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2/Conv2d_0b_3x3/weights (3x3x96x128, 110.59k/110.59k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2/Conv2d_0c_3x3 (--/147.46k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2/Conv2d_0c_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2/Conv2d_0c_3x3/weights (3x3x128x128, 147.46k/147.46k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_3 (--/73.73k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_3/Conv2d_0b_1x1 (--/73.73k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_3/Conv2d_0b_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_3/Conv2d_0b_1x1/weights (1x1x576x128, 73.73k/73.73k params)\n",
            "      FirstStageFeatureExtractor/InceptionV2/Mixed_4c (--/663.55k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_0 (--/110.59k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_0/Conv2d_0a_1x1 (--/110.59k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_0/Conv2d_0a_1x1/weights (1x1x576x192, 110.59k/110.59k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_1 (--/165.89k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_1/Conv2d_0a_1x1 (--/55.30k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_1/Conv2d_0a_1x1/weights (1x1x576x96, 55.30k/55.30k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_1/Conv2d_0b_3x3 (--/110.59k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_1/Conv2d_0b_3x3/weights (3x3x96x128, 110.59k/110.59k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2 (--/313.34k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2/Conv2d_0a_1x1 (--/55.30k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2/Conv2d_0a_1x1/weights (1x1x576x96, 55.30k/55.30k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2/Conv2d_0b_3x3 (--/110.59k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2/Conv2d_0b_3x3/weights (3x3x96x128, 110.59k/110.59k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2/Conv2d_0c_3x3 (--/147.46k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2/Conv2d_0c_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2/Conv2d_0c_3x3/weights (3x3x128x128, 147.46k/147.46k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_3 (--/73.73k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_3/Conv2d_0b_1x1 (--/73.73k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_3/Conv2d_0b_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_3/Conv2d_0b_1x1/weights (1x1x576x128, 73.73k/73.73k params)\n",
            "      FirstStageFeatureExtractor/InceptionV2/Mixed_4d (--/893.95k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_0 (--/92.16k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_0/Conv2d_0a_1x1 (--/92.16k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_0/Conv2d_0a_1x1/weights (1x1x576x160, 92.16k/92.16k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_1 (--/258.05k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_1/Conv2d_0a_1x1 (--/73.73k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_1/Conv2d_0a_1x1/weights (1x1x576x128, 73.73k/73.73k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_1/Conv2d_0b_3x3 (--/184.32k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_1/Conv2d_0b_3x3/weights (3x3x128x160, 184.32k/184.32k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2 (--/488.45k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2/Conv2d_0a_1x1 (--/73.73k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2/Conv2d_0a_1x1/weights (1x1x576x128, 73.73k/73.73k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2/Conv2d_0b_3x3 (--/184.32k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2/Conv2d_0b_3x3/weights (3x3x128x160, 184.32k/184.32k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2/Conv2d_0c_3x3 (--/230.40k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2/Conv2d_0c_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2/Conv2d_0c_3x3/weights (3x3x160x160, 230.40k/230.40k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_3 (--/55.30k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_3/Conv2d_0b_1x1 (--/55.30k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_3/Conv2d_0b_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_3/Conv2d_0b_1x1/weights (1x1x576x96, 55.30k/55.30k params)\n",
            "      FirstStageFeatureExtractor/InceptionV2/Mixed_4e (--/1.11m params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_0 (--/55.30k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_0/Conv2d_0a_1x1 (--/55.30k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_0/Conv2d_0a_1x1/weights (1x1x576x96, 55.30k/55.30k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_1 (--/294.91k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_1/Conv2d_0a_1x1 (--/73.73k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_1/Conv2d_0a_1x1/weights (1x1x576x128, 73.73k/73.73k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_1/Conv2d_0b_3x3 (--/221.18k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_1/Conv2d_0b_3x3/weights (3x3x128x192, 221.18k/221.18k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2 (--/700.42k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2/Conv2d_0a_1x1 (--/92.16k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2/Conv2d_0a_1x1/weights (1x1x576x160, 92.16k/92.16k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2/Conv2d_0b_3x3 (--/276.48k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2/Conv2d_0b_3x3/weights (3x3x160x192, 276.48k/276.48k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2/Conv2d_0c_3x3 (--/331.78k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2/Conv2d_0c_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2/Conv2d_0c_3x3/weights (3x3x192x192, 331.78k/331.78k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_3 (--/55.30k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_3/Conv2d_0b_1x1 (--/55.30k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_3/Conv2d_0b_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_3/Conv2d_0b_1x1/weights (1x1x576x96, 55.30k/55.30k params)\n",
            "  SecondStageBoxPredictor (--/16.40k params)\n",
            "    SecondStageBoxPredictor/BoxEncodingPredictor (--/12.30k params)\n",
            "      SecondStageBoxPredictor/BoxEncodingPredictor/biases (12, 12/12 params)\n",
            "      SecondStageBoxPredictor/BoxEncodingPredictor/weights (1024x12, 12.29k/12.29k params)\n",
            "    SecondStageBoxPredictor/ClassPredictor (--/4.10k params)\n",
            "      SecondStageBoxPredictor/ClassPredictor/biases (4, 4/4 params)\n",
            "      SecondStageBoxPredictor/ClassPredictor/weights (1024x4, 4.10k/4.10k params)\n",
            "  SecondStageFeatureExtractor (--/5.89m params)\n",
            "    SecondStageFeatureExtractor/InceptionV2 (--/5.89m params)\n",
            "      SecondStageFeatureExtractor/InceptionV2/Mixed_5a (--/1.44m params)\n",
            "        SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_0 (--/294.91k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_0/Conv2d_0a_1x1 (--/73.73k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_0/Conv2d_0a_1x1/weights (1x1x576x128, 73.73k/73.73k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_0/Conv2d_1a_3x3 (--/221.18k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_0/Conv2d_1a_3x3/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_0/Conv2d_1a_3x3/weights (3x3x128x192, 221.18k/221.18k params)\n",
            "        SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1 (--/1.14m params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1/Conv2d_0a_1x1 (--/110.59k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1/Conv2d_0a_1x1/weights (1x1x576x192, 110.59k/110.59k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1/Conv2d_0b_3x3 (--/442.37k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1/Conv2d_0b_3x3/weights (3x3x192x256, 442.37k/442.37k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1/Conv2d_1a_3x3 (--/589.82k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1/Conv2d_1a_3x3/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1/Conv2d_1a_3x3/weights (3x3x256x256, 589.82k/589.82k params)\n",
            "      SecondStageFeatureExtractor/InceptionV2/Mixed_5b (--/2.18m params)\n",
            "        SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_0 (--/360.45k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_0/Conv2d_0a_1x1 (--/360.45k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_0/Conv2d_0a_1x1/weights (1x1x1024x352, 360.45k/360.45k params)\n",
            "        SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_1 (--/749.57k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_1/Conv2d_0a_1x1 (--/196.61k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_1/Conv2d_0a_1x1/weights (1x1x1024x192, 196.61k/196.61k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_1/Conv2d_0b_3x3 (--/552.96k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_1/Conv2d_0b_3x3/weights (3x3x192x320, 552.96k/552.96k params)\n",
            "        SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2 (--/937.98k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2/Conv2d_0a_1x1 (--/163.84k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2/Conv2d_0a_1x1/weights (1x1x1024x160, 163.84k/163.84k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2/Conv2d_0b_3x3 (--/322.56k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2/Conv2d_0b_3x3/weights (3x3x160x224, 322.56k/322.56k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2/Conv2d_0c_3x3 (--/451.58k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2/Conv2d_0c_3x3/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2/Conv2d_0c_3x3/weights (3x3x224x224, 451.58k/451.58k params)\n",
            "        SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_3 (--/131.07k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_3/Conv2d_0b_1x1 (--/131.07k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_3/Conv2d_0b_1x1/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_3/Conv2d_0b_1x1/weights (1x1x1024x128, 131.07k/131.07k params)\n",
            "      SecondStageFeatureExtractor/InceptionV2/Mixed_5c (--/2.28m params)\n",
            "        SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_0 (--/360.45k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_0/Conv2d_0a_1x1 (--/360.45k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_0/Conv2d_0a_1x1/weights (1x1x1024x352, 360.45k/360.45k params)\n",
            "        SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_1 (--/749.57k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_1/Conv2d_0a_1x1 (--/196.61k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_1/Conv2d_0a_1x1/weights (1x1x1024x192, 196.61k/196.61k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_1/Conv2d_0b_3x3 (--/552.96k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_1/Conv2d_0b_3x3/weights (3x3x192x320, 552.96k/552.96k params)\n",
            "        SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2 (--/1.04m params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2/Conv2d_0a_1x1 (--/196.61k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2/Conv2d_0a_1x1/weights (1x1x1024x192, 196.61k/196.61k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2/Conv2d_0b_3x3 (--/387.07k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2/Conv2d_0b_3x3/weights (3x3x192x224, 387.07k/387.07k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2/Conv2d_0c_3x3 (--/451.58k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2/Conv2d_0c_3x3/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2/Conv2d_0c_3x3/weights (3x3x224x224, 451.58k/451.58k params)\n",
            "        SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_3 (--/131.07k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_3/Conv2d_0b_1x1 (--/131.07k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_3/Conv2d_0b_1x1/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_3/Conv2d_0b_1x1/weights (1x1x1024x128, 131.07k/131.07k params)\n",
            "\n",
            "======================End of Report==========================\n",
            "236 ops no flops stats due to incomplete shapes.\n",
            "Parsing Inputs...\n",
            "Incomplete shape.\n",
            "\n",
            "=========================Options=============================\n",
            "-max_depth                  10000\n",
            "-min_bytes                  0\n",
            "-min_peak_bytes             0\n",
            "-min_residual_bytes         0\n",
            "-min_output_bytes           0\n",
            "-min_micros                 0\n",
            "-min_accelerator_micros     0\n",
            "-min_cpu_micros             0\n",
            "-min_params                 0\n",
            "-min_float_ops              1\n",
            "-min_occurrence             0\n",
            "-step                       -1\n",
            "-order_by                   float_ops\n",
            "-account_type_regexes       .*\n",
            "-start_name_regexes         .*\n",
            "-trim_name_regexes          .*BatchNorm.*,.*Initializer.*,.*Regularizer.*,.*BiasAdd.*\n",
            "-show_name_regexes          .*\n",
            "-hide_name_regexes          \n",
            "-account_displayed_op_only  true\n",
            "-select                     float_ops\n",
            "-output                     stdout:\n",
            "\n",
            "==================Model Analysis Report======================\n",
            "Incomplete shape.\n",
            "\n",
            "Doc:\n",
            "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
            "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
            "\n",
            "Profile:\n",
            "node name | # float_ops\n",
            "_TFProfRoot (--/6.17k flops)\n",
            "  map/while/ToNormalizedCoordinates/Scale/mul (300/300 flops)\n",
            "  SecondStagePostprocessor/map/while/ClipToWindow/Maximum_1 (300/300 flops)\n",
            "  SecondStagePostprocessor/map/while/ClipToWindow/Maximum_2 (300/300 flops)\n",
            "  SecondStagePostprocessor/map/while/ClipToWindow/Maximum_3 (300/300 flops)\n",
            "  SecondStagePostprocessor/map/while/ClipToWindow/Minimum (300/300 flops)\n",
            "  SecondStagePostprocessor/map/while/ClipToWindow/Minimum_1 (300/300 flops)\n",
            "  SecondStagePostprocessor/map/while/ClipToWindow/Minimum_2 (300/300 flops)\n",
            "  SecondStagePostprocessor/map/while/ClipToWindow/Minimum_3 (300/300 flops)\n",
            "  SecondStagePostprocessor/map/while/ClipToWindow/Maximum (300/300 flops)\n",
            "  SecondStagePostprocessor/map/while/ToNormalizedCoordinates/Scale/mul (300/300 flops)\n",
            "  SecondStagePostprocessor/map/while/ToNormalizedCoordinates/Scale/mul_1 (300/300 flops)\n",
            "  SecondStagePostprocessor/map/while/ToNormalizedCoordinates/Scale/mul_2 (300/300 flops)\n",
            "  SecondStagePostprocessor/map/while/ToNormalizedCoordinates/Scale/mul_3 (300/300 flops)\n",
            "  map/while/ToNormalizedCoordinates/Scale/mul_1 (300/300 flops)\n",
            "  map/while/ToNormalizedCoordinates/Scale/mul_2 (300/300 flops)\n",
            "  map/while/ToNormalizedCoordinates/Scale/mul_3 (300/300 flops)\n",
            "  map_2/while/mul_3 (300/300 flops)\n",
            "  map_2/while/mul_2 (300/300 flops)\n",
            "  map_2/while/mul_1 (300/300 flops)\n",
            "  map_2/while/mul (300/300 flops)\n",
            "  GridAnchorGenerator/mul_1 (12/12 flops)\n",
            "  GridAnchorGenerator/truediv (12/12 flops)\n",
            "  GridAnchorGenerator/mul_2 (12/12 flops)\n",
            "  GridAnchorGenerator/mul (12/12 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_11 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_12 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_9 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_13 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_14 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_15 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_1 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_10 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_16 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_7 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_8 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_7 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_6 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_5 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_4 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_3 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_2 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_1 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_5 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_4 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_3 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_2 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_1 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub (1/1 flops)\n",
            "  SecondStagePostprocessor/map/while/ToNormalizedCoordinates/truediv (1/1 flops)\n",
            "  mul (1/1 flops)\n",
            "  map_2/while/Less_1 (1/1 flops)\n",
            "  map_2/while/Less (1/1 flops)\n",
            "  map_1/while/ToNormalizedCoordinates/truediv_1 (1/1 flops)\n",
            "  map_1/while/ToNormalizedCoordinates/truediv (1/1 flops)\n",
            "  map_1/while/Less_1 (1/1 flops)\n",
            "  map_1/while/Less (1/1 flops)\n",
            "  map/while/ToNormalizedCoordinates/truediv_1 (1/1 flops)\n",
            "  map/while/ToNormalizedCoordinates/truediv (1/1 flops)\n",
            "  map/while/Less_1 (1/1 flops)\n",
            "  map/while/Less (1/1 flops)\n",
            "  SecondStagePostprocessor/map/while/ToNormalizedCoordinates/truediv_1 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_17 (1/1 flops)\n",
            "  SecondStagePostprocessor/map/while/Less_1 (1/1 flops)\n",
            "  SecondStagePostprocessor/map/while/Less (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_9 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_8 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_3 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_6 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_5 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_4 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_3 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_2 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_19 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_18 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_17 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_1 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_10 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_11 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_12 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_13 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_14 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_15 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_16 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_2 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_3 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_4 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_5 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_6 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_7 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_8 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_9 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/Less_1 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Greater (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_1 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField/Equal (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField_1/Equal (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_1 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/ones/Less (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_1 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_2 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_3 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_4 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_5 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_6 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_7 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_8 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/sub_1 (1/1 flops)\n",
            "  Preprocessor/map/while/ResizeToRange/cond/resize_1/truediv (1/1 flops)\n",
            "  Preprocessor/map/while/ResizeToRange/cond/resize_1/truediv_1 (1/1 flops)\n",
            "  SecondStageDetectionFeaturesExtract/mul (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchGather/mul (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchGather/mul_2 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/Less (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/Less_1 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/sub (1/1 flops)\n",
            "  Preprocessor/map/while/ResizeToRange/cond/resize_1/mul_1 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/truediv (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/truediv_1 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Greater (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_1 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_2 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/Less (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField/Equal (1/1 flops)\n",
            "  Preprocessor/map/while/ResizeToRange/Less (1/1 flops)\n",
            "  FirstStageFeatureExtractor/GreaterEqual (1/1 flops)\n",
            "  FirstStageFeatureExtractor/GreaterEqual_1 (1/1 flops)\n",
            "  GridAnchorGenerator/assert_equal_1/Equal (1/1 flops)\n",
            "  GridAnchorGenerator/mul_7 (1/1 flops)\n",
            "  GridAnchorGenerator/mul_8 (1/1 flops)\n",
            "  GridAnchorGenerator/zeros/Less (1/1 flops)\n",
            "  Preprocessor/map/while/Less (1/1 flops)\n",
            "  Preprocessor/map/while/Less_1 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField_1/Equal (1/1 flops)\n",
            "  Preprocessor/map/while/ResizeToRange/cond/resize/Minimum (1/1 flops)\n",
            "  Preprocessor/map/while/ResizeToRange/cond/resize/mul (1/1 flops)\n",
            "  Preprocessor/map/while/ResizeToRange/cond/resize/mul_1 (1/1 flops)\n",
            "  Preprocessor/map/while/ResizeToRange/cond/resize/truediv (1/1 flops)\n",
            "  Preprocessor/map/while/ResizeToRange/cond/resize/truediv_1 (1/1 flops)\n",
            "  Preprocessor/map/while/ResizeToRange/cond/resize_1/Minimum (1/1 flops)\n",
            "  Preprocessor/map/while/ResizeToRange/cond/resize_1/mul (1/1 flops)\n",
            "\n",
            "======================End of Report==========================\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:432: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "W0412 23:24:56.377871 140044693362560 module_wrapper.py:139] From /content/models/research/object_detection/exporter.py:432: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:342: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "W0412 23:24:57.250304 140044693362560 module_wrapper.py:139] From /content/models/research/object_detection/exporter.py:342: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "2020-04-12 23:24:57.251591: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-04-12 23:24:57.291684: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-04-12 23:24:57.292255: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-04-12 23:24:57.292568: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2020-04-12 23:24:57.293996: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2020-04-12 23:24:57.295283: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2020-04-12 23:24:57.295755: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2020-04-12 23:24:57.297267: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2020-04-12 23:24:57.305853: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2020-04-12 23:24:57.320228: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-04-12 23:24:57.320397: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-04-12 23:24:57.321007: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-04-12 23:24:57.321511: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2020-04-12 23:24:57.321868: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n",
            "2020-04-12 23:24:57.326695: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2000170000 Hz\n",
            "2020-04-12 23:24:57.326877: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x219ef40 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-04-12 23:24:57.326907: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-04-12 23:24:57.442552: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-04-12 23:24:57.443241: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x219f100 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-04-12 23:24:57.443276: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2020-04-12 23:24:57.443448: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-04-12 23:24:57.443985: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-04-12 23:24:57.444082: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2020-04-12 23:24:57.444122: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2020-04-12 23:24:57.444146: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2020-04-12 23:24:57.444170: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2020-04-12 23:24:57.444190: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2020-04-12 23:24:57.444208: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2020-04-12 23:24:57.444231: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-04-12 23:24:57.444305: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-04-12 23:24:57.444906: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-04-12 23:24:57.445392: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2020-04-12 23:24:57.445451: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2020-04-12 23:24:57.446559: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-04-12 23:24:57.446587: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2020-04-12 23:24:57.446598: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2020-04-12 23:24:57.446709: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-04-12 23:24:57.447307: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-04-12 23:24:57.447840: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2020-04-12 23:24:57.447878: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14221 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-627\n",
            "I0412 23:24:57.449491 140044693362560 saver.py:1284] Restoring parameters from training/model.ckpt-627\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "W0412 23:24:59.226453 140044693362560 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "2020-04-12 23:24:59.903682: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-04-12 23:24:59.904265: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-04-12 23:24:59.904365: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2020-04-12 23:24:59.904388: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2020-04-12 23:24:59.904409: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2020-04-12 23:24:59.904434: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2020-04-12 23:24:59.904467: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2020-04-12 23:24:59.904483: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2020-04-12 23:24:59.904503: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-04-12 23:24:59.904587: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-04-12 23:24:59.905124: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-04-12 23:24:59.905595: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2020-04-12 23:24:59.905633: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-04-12 23:24:59.905647: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2020-04-12 23:24:59.905656: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2020-04-12 23:24:59.905745: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-04-12 23:24:59.906272: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-04-12 23:24:59.906755: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14221 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-627\n",
            "I0412 23:24:59.907732 140044693362560 saver.py:1284] Restoring parameters from training/model.ckpt-627\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
            "W0412 23:25:00.573629 140044693362560 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
            "W0412 23:25:00.573880 140044693362560 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
            "INFO:tensorflow:Froze 356 variables.\n",
            "I0412 23:25:00.943620 140044693362560 graph_util_impl.py:334] Froze 356 variables.\n",
            "INFO:tensorflow:Converted 356 variables to const ops.\n",
            "I0412 23:25:01.055395 140044693362560 graph_util_impl.py:394] Converted 356 variables to const ops.\n",
            "2020-04-12 23:25:01.262587: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-04-12 23:25:01.263158: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-04-12 23:25:01.263261: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2020-04-12 23:25:01.263297: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2020-04-12 23:25:01.263321: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2020-04-12 23:25:01.263343: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2020-04-12 23:25:01.263362: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2020-04-12 23:25:01.263384: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2020-04-12 23:25:01.263407: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-04-12 23:25:01.263497: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-04-12 23:25:01.264044: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-04-12 23:25:01.264507: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2020-04-12 23:25:01.264547: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-04-12 23:25:01.264561: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2020-04-12 23:25:01.264570: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2020-04-12 23:25:01.264662: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-04-12 23:25:01.265197: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-04-12 23:25:01.265676: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14221 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:306: The name tf.saved_model.builder.SavedModelBuilder is deprecated. Please use tf.compat.v1.saved_model.builder.SavedModelBuilder instead.\n",
            "\n",
            "W0412 23:25:01.676486 140044693362560 module_wrapper.py:139] From /content/models/research/object_detection/exporter.py:306: The name tf.saved_model.builder.SavedModelBuilder is deprecated. Please use tf.compat.v1.saved_model.builder.SavedModelBuilder instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:309: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
            "W0412 23:25:01.676940 140044693362560 deprecation.py:323] From /content/models/research/object_detection/exporter.py:309: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:315: The name tf.saved_model.signature_def_utils.build_signature_def is deprecated. Please use tf.compat.v1.saved_model.signature_def_utils.build_signature_def instead.\n",
            "\n",
            "W0412 23:25:01.677413 140044693362560 module_wrapper.py:139] From /content/models/research/object_detection/exporter.py:315: The name tf.saved_model.signature_def_utils.build_signature_def is deprecated. Please use tf.compat.v1.saved_model.signature_def_utils.build_signature_def instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:318: The name tf.saved_model.signature_constants.PREDICT_METHOD_NAME is deprecated. Please use tf.saved_model.PREDICT_METHOD_NAME instead.\n",
            "\n",
            "W0412 23:25:01.677604 140044693362560 module_wrapper.py:139] From /content/models/research/object_detection/exporter.py:318: The name tf.saved_model.signature_constants.PREDICT_METHOD_NAME is deprecated. Please use tf.saved_model.PREDICT_METHOD_NAME instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:323: The name tf.saved_model.tag_constants.SERVING is deprecated. Please use tf.saved_model.SERVING instead.\n",
            "\n",
            "W0412 23:25:01.677829 140044693362560 module_wrapper.py:139] From /content/models/research/object_detection/exporter.py:323: The name tf.saved_model.tag_constants.SERVING is deprecated. Please use tf.saved_model.SERVING instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:325: The name tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY is deprecated. Please use tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY instead.\n",
            "\n",
            "W0412 23:25:01.677973 140044693362560 module_wrapper.py:139] From /content/models/research/object_detection/exporter.py:325: The name tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY is deprecated. Please use tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY instead.\n",
            "\n",
            "INFO:tensorflow:No assets to save.\n",
            "I0412 23:25:01.678252 140044693362560 builder_impl.py:640] No assets to save.\n",
            "INFO:tensorflow:No assets to write.\n",
            "I0412 23:25:01.678349 140044693362560 builder_impl.py:460] No assets to write.\n",
            "INFO:tensorflow:SavedModel written to: ./fine_tuned_model/saved_model/saved_model.pb\n",
            "I0412 23:25:02.024183 140044693362560 builder_impl.py:425] SavedModel written to: ./fine_tuned_model/saved_model/saved_model.pb\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/utils/config_util.py:188: The name tf.gfile.Open is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "W0412 23:25:02.089669 140044693362560 module_wrapper.py:139] From /content/models/research/object_detection/utils/config_util.py:188: The name tf.gfile.Open is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "INFO:tensorflow:Writing pipeline config file to ./fine_tuned_model/pipeline.config\n",
            "I0412 23:25:02.090012 140044693362560 config_util.py:190] Writing pipeline config file to ./fine_tuned_model/pipeline.config\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "usgBZvkz0nqD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "edbc882d-2e7b-4f8c-e5de-42ba790a0e1e"
      },
      "source": [
        "!ls {output_directory}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "checkpoint\t\t\tmodel.ckpt.index  saved_model\n",
            "frozen_inference_graph.pb\tmodel.ckpt.meta\n",
            "model.ckpt.data-00000-of-00001\tpipeline.config\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p09AOThWkaQv"
      },
      "source": [
        "## Download the model `.pb` file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CnDo1lonKgFr"
      },
      "source": [
        "import os\n",
        "\n",
        "pb_fname = os.path.join(os.path.abspath(output_directory), \"frozen_inference_graph.pb\")\n",
        "assert os.path.isfile(pb_fname), '`{}` not exist'.format(pb_fname)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lHqWkLBINYoI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d3ac3fe9-38f4-4b21-ce21-02d8b82582aa"
      },
      "source": [
        "!ls -alh {pb_fname}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-rw-r--r-- 1 root root 50M Apr 12 23:25 /content/models/research/fine_tuned_model/frozen_inference_graph.pb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FIqnjbWYsuQw"
      },
      "source": [
        "### Option1 : upload the `.pb` file to your Google Drive\n",
        "Then download it from your Google Drive to local file system.\n",
        "\n",
        "During this step, you will be prompted to enter the token."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hAqyASIJqjae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "outputId": "6567fe0c-3f8f-4502-9e24-c1c1ef2963e8"
      },
      "source": [
        "# Install the PyDrive wrapper & import libraries.\n",
        "# This only needs to be done once in a notebook.\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "# This only needs to be done once in a notebook.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "fname = os.path.basename(pb_fname)\n",
        "# Create & upload a text file.\n",
        "uploaded = drive.CreateFile({'title': fname})\n",
        "uploaded.SetContentFile(pb_fname)\n",
        "uploaded.Upload()\n",
        "print('Uploaded file with ID {}'.format(uploaded.get('id')))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to the following link in your browser:\n",
            "\n",
            "    https://accounts.google.com/o/oauth2/auth?code_challenge=XmuAbEshuMer9xCPk8IShCVSOxSBZSZjsZsyOSvpSDs&prompt=select_account&code_challenge_method=S256&access_type=offline&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&response_type=code&client_id=32555940559.apps.googleusercontent.com&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fuserinfo.email+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcloud-platform+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fappengine.admin+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcompute+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Faccounts.reauth+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive\n",
            "\n",
            "Enter verification code: ··········\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "AuthorizationError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAuthorizationError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-686862cc373a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Authenticate and create the PyDrive client.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# This only needs to be done once in a notebook.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mauth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauthenticate_user\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mgauth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGoogleAuth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mgauth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcredentials\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGoogleCredentials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_application_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/auth.py\u001b[0m in \u001b[0;36mauthenticate_user\u001b[0;34m(clear_output)\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0mcontext_manager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtemporary\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mclear_output\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0m_noop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mcontext_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m       \u001b[0m_gcloud_login\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m     \u001b[0m_install_adc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0mcolab_tpu_addr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'COLAB_TPU_ADDR'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/auth.py\u001b[0m in \u001b[0;36m_gcloud_login\u001b[0;34m()\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mgcloud_process\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0m_errors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAuthorizationError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Error fetching credentials'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAuthorizationError\u001b[0m: Error fetching credentials"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2FKFq8RXs6bs"
      },
      "source": [
        "### Option2 :  Download the `.pb` file directly to your local file system\n",
        "This method may not be stable when downloading large files like the model `.pb` file. Try **option 1** instead if not working."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bP0iMMnnr77"
      },
      "source": [
        "from google.colab import files\n",
        "files.download(pb_fname)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFyCeiBb9BbS"
      },
      "source": [
        "### OPTIONAL: Download the `label_map.pbtxt` file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1TbL6Ox8q6Z"
      },
      "source": [
        "from google.colab import files\n",
        "files.download(label_map_pbtxt_fname)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iUmAo9foa1xq"
      },
      "source": [
        "### OPTIONAL: Download the modified pipline file\n",
        "If you plan to use OpenVINO toolkit to convert the `.pb` file to inference faster on Intel's hardware (CPU/GPU, Movidius, etc.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pql2QpemazE1"
      },
      "source": [
        "files.download(pipeline_fname)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1AgBj1l0v_W"
      },
      "source": [
        "# !tar cfz fine_tuned_model.tar.gz fine_tuned_model\n",
        "# from google.colab import files\n",
        "# files.download('fine_tuned_model.tar.gz')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lnx57Mbe72yY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45ENiVg_74Lf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "3fbac66d-344d-4127-9ff5-5114d4bea248"
      },
      "source": [
        "# optionally, remove the TFRecord and cells_label_map.pbtxt from\n",
        "# the test directory so it is only raw images\n",
        "%cd {repo_dir_path}\n",
        "%cd data/test\n",
        "%rm cells.tfrecord\n",
        "%rm cells_label_map.pbtxt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/tensorflow-object-detection-faster-rcnn\n",
            "/content/tensorflow-object-detection-faster-rcnn/data/test\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pzj9A4e5mj5l",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "1cf77694-1486-4a54-ad8b-89e1bf9b33f8"
      },
      "source": [
        "import os\n",
        "import glob\n",
        "\n",
        "# Path to frozen detection graph. This is the actual model that is used for the object detection.\n",
        "PATH_TO_CKPT = pb_fname\n",
        "\n",
        "# List of the strings that is used to add correct label for each box.\n",
        "PATH_TO_LABELS = label_map_pbtxt_fname\n",
        "\n",
        "# If you want to test the code with your images, just add images files to the PATH_TO_TEST_IMAGES_DIR.\n",
        "PATH_TO_TEST_IMAGES_DIR =  os.path.join(repo_dir_path, \"data/test\")\n",
        "\n",
        "assert os.path.isfile(pb_fname)\n",
        "assert os.path.isfile(PATH_TO_LABELS)\n",
        "if len(TEST_IMAGE_PATHS) == 0:\n",
        "  sample_img = 'https://storage.googleapis.com/roboflow-platform-transforms/Ly2DeBzbwsemGd2ReHk4BFxy8683/cf5ed147e4f2675fbabbc9b0db750ecf/transformed.jpg'\n",
        "  import urllib.request\n",
        "  urllib.request.urlretrieve(sample_img, \n",
        "                            PATH_TO_TEST_IMAGES_DIR + \"/cell.jpg\")\n",
        "\n",
        "TEST_IMAGE_PATHS = glob.glob(os.path.join(PATH_TO_TEST_IMAGES_DIR, \"*.*\"))\n",
        "assert len(TEST_IMAGE_PATHS) > 0, 'No image found in `{}`.'.format(PATH_TO_TEST_IMAGES_DIR)\n",
        "print(TEST_IMAGE_PATHS)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['/content/tensorflow-object-detection-faster-rcnn/data/test/BloodImage_00284_jpg.rf.d33fcb37af7c55a50f275711763ddf7a.jpg', '/content/tensorflow-object-detection-faster-rcnn/data/test/BloodImage_00302_jpg.rf.ae0f61c17483b2e0e7f9b1396fc5108c.jpg', '/content/tensorflow-object-detection-faster-rcnn/data/test/BloodImage_00062_jpg.rf.e965ee152eea462d82706a2709abfe00.jpg', '/content/tensorflow-object-detection-faster-rcnn/data/test/BloodImage_00359_jpg.rf.e4b6af6691f2d8cc8345f42bcc1678fa.jpg', '/content/tensorflow-object-detection-faster-rcnn/data/test/BloodImage_00227_jpg.rf.1572183909350ffe748751e967b7c8e5.jpg', '/content/tensorflow-object-detection-faster-rcnn/data/test/BloodImage_00336_jpg.rf.5ae87ede3994ca14504136035e256e38.jpg', '/content/tensorflow-object-detection-faster-rcnn/data/test/BloodImage_00112_jpg.rf.f8d86689750221da637a054843c72822.jpg', '/content/tensorflow-object-detection-faster-rcnn/data/test/BloodImage_00154_jpg.rf.7c682b32a64ca0520b6fc725f0d667c7.jpg', '/content/tensorflow-object-detection-faster-rcnn/data/test/BloodImage_00044_jpg.rf.b0e2369642c5a7fa434ed8defa79e2ba.jpg', '/content/tensorflow-object-detection-faster-rcnn/data/test/BloodImage_00133_jpg.rf.06c3705fcfe2fcaee19e1a076e511508.jpg', '/content/tensorflow-object-detection-faster-rcnn/data/test/BloodImage_00325_jpg.rf.55e62842be833601c86a1bd449ee8fe6.jpg', '/content/tensorflow-object-detection-faster-rcnn/data/test/BloodImage_00266_jpg.rf.6d62684a33e2f5bc048803aba3177f58.jpg', '/content/tensorflow-object-detection-faster-rcnn/data/test/BloodImage_00254_jpg.rf.6e046ca48ec2e57c2e178aa3f08ec8ee.jpg', '/content/tensorflow-object-detection-faster-rcnn/data/test/BloodImage_00241_jpg.rf.d0edd8c528bec298a9552ed8ad5714c7.jpg', '/content/tensorflow-object-detection-faster-rcnn/data/test/BloodImage_00334_jpg.rf.3b8a84d57940aeb45e5c2046c8411996.jpg', '/content/tensorflow-object-detection-faster-rcnn/data/test/BloodImage_00235_jpg.rf.b01cbde1f504d448759188feadad4838.jpg', '/content/tensorflow-object-detection-faster-rcnn/data/test/BloodImage_00090_jpg.rf.4fd1da847d2857b6092003c41255ea4c.jpg', '/content/tensorflow-object-detection-faster-rcnn/data/test/BloodImage_00038_jpg.rf.63da20f3f5538d0d2be8c4633c7034a1.jpg', '/content/tensorflow-object-detection-faster-rcnn/data/test/BloodImage_00337_jpg.rf.7959cb18929c970939cda4a9544547c8.jpg', '/content/tensorflow-object-detection-faster-rcnn/data/test/BloodImage_00278_jpg.rf.9ce9e9760ff20b56b115c86879e02a67.jpg', '/content/tensorflow-object-detection-faster-rcnn/data/test/BloodImage_00160_jpg.rf.500f16e32681898ca1ce052ea0402c08.jpg', '/content/tensorflow-object-detection-faster-rcnn/data/test/BloodImage_00301_jpg.rf.9c427e66bcc1b088df9a5e71c0abefba.jpg', '/content/tensorflow-object-detection-faster-rcnn/data/test/BloodImage_00385_jpg.rf.cf0e48c08597f372423a60918074f574.jpg', '/content/tensorflow-object-detection-faster-rcnn/data/test/BloodImage_00113_jpg.rf.a6d6a75c0ebfc703ecff95e2938be34d.jpg', '/content/tensorflow-object-detection-faster-rcnn/data/test/BloodImage_00289_jpg.rf.58c541d9273174738d3d74e599428169.jpg', '/content/tensorflow-object-detection-faster-rcnn/data/test/BloodImage_00120_jpg.rf.6742a4da047e1226a181d2de2978ce6d.jpg', '/content/tensorflow-object-detection-faster-rcnn/data/test/BloodImage_00386_jpg.rf.1de8e2e0e94f942d7a1523852d7fb146.jpg', '/content/tensorflow-object-detection-faster-rcnn/data/test/BloodImage_00204_jpg.rf.6c3c9e37ab9122b026444cc4e685aef1.jpg', '/content/tensorflow-object-detection-faster-rcnn/data/test/BloodImage_00099_jpg.rf.5b178d758af2a97d3df8e5f87b1f344a.jpg', '/content/tensorflow-object-detection-faster-rcnn/data/test/BloodImage_00275_jpg.rf.9108b9a016fadd9c367b05dfb0c40c2c.jpg', '/content/tensorflow-object-detection-faster-rcnn/data/test/BloodImage_00369_jpg.rf.99ae139e5530a25980b7acdd56a4317c.jpg', '/content/tensorflow-object-detection-faster-rcnn/data/test/BloodImage_00134_jpg.rf.ee0308b1f3e1ffbb048cb3b1f80e8e36.jpg', '/content/tensorflow-object-detection-faster-rcnn/data/test/BloodImage_00265_jpg.rf.4b7cc25caca963b5e0325c6998917cd1.jpg', '/content/tensorflow-object-detection-faster-rcnn/data/test/BloodImage_00190_jpg.rf.03484116dcad7715c77d30654056fc54.jpg', '/content/tensorflow-object-detection-faster-rcnn/data/test/BloodImage_00191_jpg.rf.d4b5ad6525c6c0bc4eaea1f24901f396.jpg', '/content/tensorflow-object-detection-faster-rcnn/data/test/BloodImage_00350_jpg.rf.1a19e9f9f197fbeab278718f7c6cea9b.jpg']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNFc5CM3Duav",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "37a1477d-7382-4e77-9b4f-eb69bc104b02"
      },
      "source": [
        "%cd /content/models/research/object_detection\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import six.moves.urllib as urllib\n",
        "import sys\n",
        "import tarfile\n",
        "import tensorflow as tf\n",
        "import zipfile\n",
        "\n",
        "from collections import defaultdict\n",
        "from io import StringIO\n",
        "from matplotlib import pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "# This is needed since the notebook is stored in the object_detection folder.\n",
        "sys.path.append(\"..\")\n",
        "from object_detection.utils import ops as utils_ops\n",
        "\n",
        "\n",
        "# This is needed to display the images.\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "from object_detection.utils import label_map_util\n",
        "\n",
        "from object_detection.utils import visualization_utils as vis_util"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/models/research/object_detection\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CG5YUMdg1Po7"
      },
      "source": [
        "detection_graph = tf.Graph()\n",
        "with detection_graph.as_default():\n",
        "    od_graph_def = tf.GraphDef()\n",
        "    with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
        "        serialized_graph = fid.read()\n",
        "        od_graph_def.ParseFromString(serialized_graph)\n",
        "        tf.import_graph_def(od_graph_def, name='')\n",
        "\n",
        "\n",
        "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
        "categories = label_map_util.convert_label_map_to_categories(\n",
        "    label_map, max_num_classes=num_classes, use_display_name=True)\n",
        "category_index = label_map_util.create_category_index(categories)\n",
        "\n",
        "\n",
        "def load_image_into_numpy_array(image):\n",
        "    (im_width, im_height) = image.size\n",
        "    return np.array(image.getdata()).reshape(\n",
        "        (im_height, im_width, 3)).astype(np.uint8)\n",
        "\n",
        "# Size, in inches, of the output images.\n",
        "IMAGE_SIZE = (12, 8)\n",
        "\n",
        "\n",
        "def run_inference_for_single_image(image, graph):\n",
        "    with graph.as_default():\n",
        "        with tf.Session() as sess:\n",
        "            # Get handles to input and output tensors\n",
        "            ops = tf.get_default_graph().get_operations()\n",
        "            all_tensor_names = {\n",
        "                output.name for op in ops for output in op.outputs}\n",
        "            tensor_dict = {}\n",
        "            for key in [\n",
        "                'num_detections', 'detection_boxes', 'detection_scores',\n",
        "                'detection_classes', 'detection_masks'\n",
        "            ]:\n",
        "                tensor_name = key + ':0'\n",
        "                if tensor_name in all_tensor_names:\n",
        "                    tensor_dict[key] = tf.get_default_graph().get_tensor_by_name(\n",
        "                        tensor_name)\n",
        "            if 'detection_masks' in tensor_dict:\n",
        "                # The following processing is only for single image\n",
        "                detection_boxes = tf.squeeze(\n",
        "                    tensor_dict['detection_boxes'], [0])\n",
        "                detection_masks = tf.squeeze(\n",
        "                    tensor_dict['detection_masks'], [0])\n",
        "                # Reframe is required to translate mask from box coordinates to image coordinates and fit the image size.\n",
        "                real_num_detection = tf.cast(\n",
        "                    tensor_dict['num_detections'][0], tf.int32)\n",
        "                detection_boxes = tf.slice(detection_boxes, [0, 0], [\n",
        "                                           real_num_detection, -1])\n",
        "                detection_masks = tf.slice(detection_masks, [0, 0, 0], [\n",
        "                                           real_num_detection, -1, -1])\n",
        "                detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n",
        "                    detection_masks, detection_boxes, image.shape[0], image.shape[1])\n",
        "                detection_masks_reframed = tf.cast(\n",
        "                    tf.greater(detection_masks_reframed, 0.5), tf.uint8)\n",
        "                # Follow the convention by adding back the batch dimension\n",
        "                tensor_dict['detection_masks'] = tf.expand_dims(\n",
        "                    detection_masks_reframed, 0)\n",
        "            image_tensor = tf.get_default_graph().get_tensor_by_name('image_tensor:0')\n",
        "\n",
        "            # Run inference\n",
        "            output_dict = sess.run(tensor_dict,\n",
        "                                   feed_dict={image_tensor: np.expand_dims(image, 0)})\n",
        "\n",
        "            # all outputs are float32 numpy arrays, so convert types as appropriate\n",
        "            output_dict['num_detections'] = int(\n",
        "                output_dict['num_detections'][0])\n",
        "            output_dict['detection_classes'] = output_dict[\n",
        "                'detection_classes'][0].astype(np.uint8)\n",
        "            output_dict['detection_boxes'] = output_dict['detection_boxes'][0]\n",
        "            output_dict['detection_scores'] = output_dict['detection_scores'][0]\n",
        "            if 'detection_masks' in output_dict:\n",
        "                output_dict['detection_masks'] = output_dict['detection_masks'][0]\n",
        "    return output_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-IbKIjbY_MRk"
      },
      "source": [
        "# Output images not showing? Run this cell again, and try the cell above\n",
        "# This is needed to display the images.\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ah9YKYOX9qrH"
      },
      "source": [
        "\n",
        "for image_path in TEST_IMAGE_PATHS:\n",
        "    image = Image.open(image_path)\n",
        "    # the array based representation of the image will be used later in order to prepare the\n",
        "    # result image with boxes and labels on it.\n",
        "    image_np = load_image_into_numpy_array(image)\n",
        "    # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
        "    image_np_expanded = np.expand_dims(image_np, axis=0)\n",
        "    # Actual detection.\n",
        "    output_dict = run_inference_for_single_image(image_np, detection_graph)\n",
        "    # Visualization of the results of a detection.\n",
        "    vis_util.visualize_boxes_and_labels_on_image_array(\n",
        "        image_np,\n",
        "        output_dict['detection_boxes'],\n",
        "        output_dict['detection_classes'],\n",
        "        output_dict['detection_scores'],\n",
        "        category_index,\n",
        "        instance_masks=output_dict.get('detection_masks'),\n",
        "        use_normalized_coordinates=True,\n",
        "        line_thickness=8)\n",
        "    plt.figure(figsize=IMAGE_SIZE)\n",
        "    plt.imshow(image_np)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}